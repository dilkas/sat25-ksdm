\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate]{lipics-v2021}
%This is a template for producing LIPIcs articles. 
%See lipics-v2021-authors-guidelines.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for enabling a two-column layout for the author/affilation part (only applicable for > 6 authors), use "authorcolumns"
%for producing a PDF according the PDF/A standard, add "pdfa"

\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\bibliographystyle{plainurl}% the mandatory bibstyle

\title{Towards Practical First-Order Model Counting}

\author{Ananth K. Kidambi}{Indian Institute of Technology Bombay, Mumbai, India}{210051002@iitb.ac.in}{}{TODO: funding}
\author{Guramrit Singh}{Indian Institute of Technology Bombay, Mumbai, India}{guramrit@iitb.ac.in}{}{TODO: funding}
\author{Paulius Dilkas}{University of Toronto, Toronto, Canada \and Vector Institute, Toronto, Canada \and \url{https://dilkas.github.io/}}{paulius.dilkas@utoronto.ca}{https://orcid.org/0000-0001-9185-7840}{TODO: funding}
\author{Kuldeep S. Meel}{University of Toronto, Toronto, Canada \and \url{https://www.cs.toronto.edu/~meel/}}{meel@cs.toronto.edu}{https://orcid.org/0000-0001-9423-5270}{TODO: funding}

\authorrunning{A.\,K. Kidambi, G. Singh, P. Dilkas, and K.\,S. Meel}
\Copyright{Ananth K. Kidambi, Guramrit Singh, Paulius Dilkas, and Kuldeep S. Meel}

\ccsdesc{Theory of computation~Automated reasoning}
\ccsdesc{Theory of computation~Logic and verification}
\ccsdesc{Mathematics of computing~Combinatorics}

\keywords{first-order model counting, knowledge compilation, lifted inference}

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

\acknowledgements{Part of the research was conducted while all authors were at the National University of Singapore.}

%\nolinenumbers %uncomment to disable line numbering



%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{siunitx}
\usepackage{tikz}
\usepackage{microtype}

\usetikzlibrary{arrows.meta}
\usetikzlibrary{fit}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.misc}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\newcommand{\expr}{\mathtt{expr}}
\newcommand{\Ctwo}{$\mathsf{C}^{2}$}
\newcommand{\FO}{$\mathsf{FO}$}
\newcommand{\UFO}{$\mathsf{UFO}^{2} + \mathsf{CC}$}
\newcommand{\Cranetwo}{\textsc{Gantry}}
\newcommand{\Cranebfs}{\textsc{Gantry-BFS}}
\newcommand{\Cranegreedy}{\textsc{Gantry-Greedy}}

\SetKwFunction{CompileWithBaseCases}{CompileWithBaseCases}
\SetKwFunction{Compile}{{\normalfont \textsc{Crane}}}
\SetKwFunction{Propagate}{Propagate}
\SetKwFunction{FindBaseCases}{FindBaseCases}
\SetKwFunction{Simplify}{Simplify}

\DeclareMathOperator{\CR}{CR}
\DeclareMathOperator{\DR}{DR}
\DeclareMathOperator{\Reff}{Ref}
\DeclareMathOperator{\Doms}{Doms}

\sisetup{group-separator = {,}}
\newtheorem{assumption}[theorem]{Assumption}

\crefalias{enumi}{type}
\crefname{type}{Type}{Types}
\creflabelformat{type}{#2\textup{#1}#3}
\crefalias{clause}{equation}
\crefname{clause}{Clause}{Clauses}
\creflabelformat{clause}{#2\textup{(#1)}#3}
\crefalias{formula}{equation}
\crefname{formula}{Formula}{Formulas}
\creflabelformat{formula}{#2\textup{(#1)}#3}

% TODO (for the entire paper):
% * sentence vs formula: be consistent and not confusing
% * 15 pages excluding references

\begin{document}

\maketitle

\begin{abstract}
  First-order model counting (FOMC) is the problem of counting the number of
  models of a sentence in first-order logic. Since lifted inference techniques
  rely on reductions to variants of FOMC, the design of scalable methods for
  FOMC has attracted attention from both theoreticians and practitioners over
  the past decade. Recently, a new approach based on first-order knowledge
  compilation was proposed. This approach, called \textsc{Crane}, instead of
  simply providing the final count, generates definitions of (possibly
  recursive) functions that can be evaluated with different arguments to compute
  the model count for any domain size. However, this approach is not fully
  automated, as it requires manual evaluation of the constructed functions. The
  primary contribution of this work is a fully automated compilation algorithm,
  called \Cranetwo{}, which transforms the function definitions into C++ code
  equipped with arbitrary-precision arithmetic. These additions allow the new
  FOMC algorithm to scale to domain sizes over \num{500000} times larger than
  the current state of the art, as demonstrated through experimental results.
\end{abstract}

\section{Introduction}
% TODO: We would like to clarify that the main contribution of this work
% consists of everything needed to complement recursive function definitions
% with the necessary base cases. This process includes identifying the base
% cases and their corresponding formulas, transforming them (including applying
% a new smoothing procedure), and recursively reusing Crane. C++ code
% generation, although relatively straightforward, is crucial for the usability
% of the algorithm

% TODO: focus more on current work

% 1. What is the problem?
% 2. Why is it interesting and important?

\emph{First-order model counting} (FOMC) is the task of determining the number
of models for a sentence in first-order logic over a specified domain. The
weighted variant, WFOMC, computes the total weight of these models, linking
logical reasoning with probabilistic
frameworks~\cite{DBLP:conf/ijcai/BroeckTMDR11}. It builds upon earlier efforts
in weighted model counting for propositional
logic~\cite{DBLP:journals/ai/ChaviraD08} and broader attempts to bridge logic
and
probability~\cite{DBLP:journals/ai/Nilsson86,novak2012mathematical,vsaletic2024graded}.
WFOMC is central to \emph{lifted inference}, which enhances the efficiency of
probabilistic calculations by exploiting
symmetries~\cite{DBLP:conf/ecai/Kersting12}. Lifted inference continues to
advance, with applications extending to constraint satisfaction
problems~\cite{DBLP:journals/jair/TotisDRK23} and probabilistic answer set
programming~\cite{DBLP:journals/ijar/AzzoliniR23}. Moreover, WFOMC has proven
effective at reasoning over probabilistic
databases~\cite{DBLP:journals/debu/GribkoffSB14} and probabilistic logic
programs~\cite{DBLP:journals/ijar/RiguzziBZCL17}. FOMC algorithms have also
facilitated breakthroughs in discovering integer
sequences~\cite{DBLP:conf/ijcai/SvatosJT0K23} and developing recurrence
relations for these sequences~\cite{DBLP:conf/kr/DilkasB23}. Recently, these
algorithms have been extended to perform sampling
tasks~\cite{DBLP:journals/ai/WangPWK24}.

% 3. Why is it hard? (E.g., why do naive approaches fail?)

The complexity of FOMC is generally measured by \emph{data complexity}, with a
formula classified as \emph{liftable} if it can be solved in polynomial time
relative to the domain size~\cite{DBLP:conf/starai/JaegerB12}. While all
formulas with up to two variables are known to be
liftable~\cite{DBLP:conf/nips/Broeck11,DBLP:conf/kr/BroeckMD14}, Beame et
al.~\cite{DBLP:conf/pods/BeameBGS15} demonstrated that liftability does not
extend to all formulas, identifying an unliftable formula with three variables.
Recent work has further extended the liftable fragment with additional
axioms~\cite{DBLP:conf/aaai/TothK23,DBLP:journals/ai/BremenK23} and counting
quantifiers~\cite{DBLP:journals/jair/Kuzelka21}, expanding our understanding of
liftability.

% 4. Why hasn't it been solved before? (Or, what's wrong with previous proposed
% solutions? How does mine differ?)

% TODO: don't assume that the reader knows FOMC and FOMC algorithms

% TODO: It would be nice to give the necessary introduction to FOKC, or CRANE
% (an intuitive explanation early in the paper)

% TODO: The principal motivation of a knowledge compilation-based approach to
% FOMC comes from its ability to find polynomial-time solutions, where the
% polynomial has a lower degree compared to, e.g., FastWFOMC (Dilkas and Belle,
% 2023). The ability of the algorithm to mathematically describe recursive
% solutions is also noteworthy as the only other available alternative is to
% guess them (Barvı́nek, van Bremen, Wang, Zelezný, Kuzelka, ILP 2021).
FOMC algorithms are diverse, with approaches ranging from \emph{first-order
  knowledge compilation} (FOKC) to local
search~\cite{DBLP:journals/pvldb/NiuRDS11}, Monte Carlo
sampling~\cite{DBLP:journals/cacm/GogateD16}, and anytime
approximation~\cite{DBLP:conf/ijcai/BremenK20}. Among these, FOKC-based
algorithms are particularly prominent, transforming formulas into structured
representations such as circuits or graphs. Notable examples include
\textsc{ForcLift}~\cite{DBLP:conf/ijcai/BroeckTMDR11} and its successor
\textsc{Crane}~\cite{DBLP:conf/kr/DilkasB23}. Another important algorithm,
\textsc{FastWFOMC}~\cite{DBLP:conf/uai/BremenK21}, uses cell enumeration as its
foundation.

% 5. What are the key components of my approach and results? Also include any
% specific limitations.

The \textsc{Crane} algorithm marked a significant step forward, expanding the
range of formulas handled by FOMC algorithms. However, it had notable
limitations: it required manual evaluation of function definitions to compute
model counts and introduced recursive functions without proper base cases,
making it more complex to use. To address these shortcomings, we present
\Cranetwo{}, a fully automated FOMC algorithm that overcomes the constraints of
its predecessor. \Cranetwo{} can handle domain sizes over \num{500000} times
larger than previous algorithms and simplifies the user experience by
automatically handling base cases and compiling function definitions into
efficient C++ programs.

In \cref{sec:preliminaries}, we cover some preliminaries, and in
\cref{sec:main}, we detail all our technical contributions. Finally, in
\cref{sec:experiments}, we present our experimental results, demonstrating
\Cranetwo{}'s performance compared to other FOMC algorithms, and, in
\cref{sec:conclusion}, we conclude the paper by discussing promising avenues for
future work.

\section{Preliminaries}\label{sec:preliminaries}

In \cref{sec:logic}, we summarise the basic principles of first-order logic.
Then, in \cref{sec:threelogics}, we formally define (W)FOMC and discuss the
distinctions between three variations of first-order logic used for FOMC.\@
Finally, in \cref{sec:algebra}, we introduce the terminology used to describe
the output of the original \textsc{Crane} algorithm, i.e., functions and
equations that define them.

We use $\mathbb{N}_{0}$ to represent the set of non-negative integers. In both
algebra and logic, we write $S\sigma$ to denote the application of a
\emph{substitution} $\sigma$ to an expression $S$, where
$\sigma = [x_{1} \mapsto y_{1}, x_{2} \mapsto y_{2}, \dots, x_{n} \mapsto y_{n}]$
signifies the replacement of all instances of $x_{i}$ with $y_{i}$ for all
$i = 1, \dots, n$.

\subsection{First-Order Logic}\label{sec:logic}

In this section, we will review the basic concepts of first-order logic as they
are used in FOKC algorithms. We begin by introducing the format used internally
by \textsc{ForcLift} and its descendants. Afterwards, we provide a high-level
description of how an arbitrary sentence in first-order logic is transformed
into this internal format.

A \emph{term} can be either a variable or a constant. An \emph{atom} can be
either $P(t_{1}, \dots, t_{m})$ (i.e., $P(\mathbf{t})$) for some predicate $P$
and terms $t_{1}, \dots, t_{m}$ or $x=y$ for some terms $x$ and $y$. The
\emph{arity} of a predicate is the number of arguments it takes, i.e., $m$ in
the case of the predicate $P$ mentioned above. We write $P/m$ to denote a
predicate along with its arity. A \emph{literal} can be either an atom (i.e., a
\emph{positive} literal) or its negation (i.e., a \emph{negative} literal). An
atom is \emph{ground} if it contains no variables, i.e., only constants. A
\emph{clause} is of the form $\forall x_{1} \in \Delta_{1}\text{.
}\forall x_{2} \in \Delta_{2}\dots\text{ }\forall x_{n} \in \Delta_{n}\text{.
}\phi(x_{1}, x_{2}, \dots, x_{n})$, where $\phi$ is a disjunction of literals
that only contain variables $x_{1}, \dots, x_{n}$ (and any constants). We say
that a clause is a \emph{(positive) unit clause} if there is only one literal
with a predicate, and it is a positive literal. Finally, a \emph{formula} is a
conjunction of clauses. Throughout the paper, we will use set-theoretic
notation, interpreting a formula as a set of clauses and a clause as a set of
literals.

\begin{remark*}
  Conforming with previous work~\cite{DBLP:conf/ijcai/BroeckTMDR11}, the
  definition of a clause includes universal quantifiers for all variables
  within. While it is possible to rewrite the entire formula with all
  quantifiers at the front~\cite{hinman2018fundamentals}, the format we describe
  has proven itself convenient to work with.
\end{remark*}

There are two crucial preprocessing steps that transform an arbitrary sentence
in first-order logic into the form used internally: Skolemization and rewriting
the sentence as a conjunction of clauses. We describe the former in more detail.
\emph{Skolemization}~\cite{DBLP:conf/kr/BroeckMD14} is a procedure that
transforms a formula with existential quantifiers into a formula without
existential quantifiers \emph{with the same WFOMC}. (Note that it is different
from the standard Skolemization that introduces function
symbols~\cite{DBLP:books/daglib/0030198}.)

\begin{example}
  Skolemization transforms
  \begin{equation}\label[formula]{eq:skolemizationinitial}
    \forall x \in \Gamma\text{. }\exists y \in \Delta\text{. } P(x, y)
  \end{equation}
  into
  \begin{equation}\label[formula]{eq:skolemization}
    \begin{aligned}
      (\forall x \in \Gamma\text{. } &Z(x))\land{}\\
      (\forall x \in \Gamma\text{. } \forall y \in \Delta\text{. } &Z(x) \lor \neg P(x, y))\land{}\\
      (\forall x \in \Gamma\text{. } &S(x) \lor Z(x))\land{}\\
      (\forall x \in \Gamma\text{. } \forall y \in \Delta\text{. } &S(x) \lor \neg P(x, y)).
    \end{aligned}
  \end{equation}
  We will see how, with suitable weights on the new predicates $S/1$ and $Z/1$,
  the WFOMC of \cref{eq:skolemization} is equal to the FOMC of
  \cref{eq:skolemizationinitial}.
\end{example}
% TODO: make sure to revisit this in the future

\subsection{FOMC Algorithms and Their Logics}\label{sec:threelogics}

% TODO: shorten the part about the three logics

\begin{table*}[t]
  \centering
  \begin{tabular}{llclll}
    \toprule
    Logic & Sorts & Constants & Variables & Quantifiers & Additional atoms\\
    \midrule
    \FO & one or more & \cmark & unlimited & $\forall$, $\exists$ & $x = y$\\
    \Ctwo & one & \xmark & two & $\forall$, $\exists$, $\exists^{= k}$, $\exists^{\le k}$, $\exists^{\ge k}$ & ---\\
    \UFO & one & \xmark & two & $\forall$ & $|P| = m$\\
    \bottomrule
  \end{tabular}
  \caption{A comparison of the three logics used in FOMC\@. The
    2\textsuperscript{nd}--5\textsuperscript{th} columns refer to: the number of
    sorts, support for constants, the maximum number of variables, and supported
    quantifiers, respectively. The last column lists supported atoms in addition
    to those of the form $P(\mathbf{t})$ for a predicate $P/n$ and an $n$-tuple
    of terms $\mathbf{t}$. Here: $k$ and $m$ are non-negative integers, with the
    latter depending on the domain size, $P$ represents a predicate, and $x$ and
    $y$ are terms. }\label{tbl:logics}
\end{table*}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

In \cref{tbl:logics}, we outline the differences among three first-order logics
commonly used in FOMC: \FO{}, \Ctwo{}, and \UFO{}. First, \FO{} is the input
format for
\textsc{ForcLift}\footnote{\url{https://github.com/UCLA-StarAI/Forclift}} and
its extensions
\textsc{Crane}\footnote{\url{https://doi.org/10.5281/zenodo.8004077}} and
\Cranetwo{}. Second, \Ctwo{} is often used in the literature on
\textsc{FastWFOMC} and related
methods~\cite{DBLP:journals/jair/Kuzelka21,DBLP:conf/aaai/MalhotraS22}. Finally,
\UFO{} is the input format supported by the most recent implementation of
\textsc{FastWFOMC}\footnote{\url{https://github.com/jan-toth/FastWFOMC.jl}}. The
notation we use to refer to each logic is standard in the case of \Ctwo{} and
\UFO{}~\cite{tóth2024complexityweightedfirstordermodel} and redefined to be more
specific in the case of \FO{}. All three logics are function-free, and domains
are always assumed to be finite. As usual, we presuppose the \emph{unique name
  assumption}, which states that two constants are equal if and only if they are
the same constant~\cite{DBLP:books/aw/RN2020}.

\renewcommand*{\thefootnote}{\arabic{footnote}}

In \FO{}, each term is assigned to a \emph{sort}, and each predicate $P/n$ is
assigned to a sequence of $n$ sorts. Each sort has its corresponding domain.
These assignments to sorts are typically left implicit and can be reconstructed
from the quantifiers. For example, $\forall x,y \in \Delta\text{. }P(x, y)$
implies that variables $x$ and $y$ have the same sort. On the other hand,
$\forall x \in \Delta\text{. }\forall y \in \Gamma\text{. } P(x, y)$ implies
that $x$ and $y$ have different sorts, and it would be improper to write, for
example, $\forall x \in \Delta\text{. }\forall y \in \Gamma\text{.
} P(x, y) \lor x = y$. \FO{} is also the only logic to support constants,
formulas with more than two variables, and the equality predicate. While we do
not explicitly refer to sorts in subsequent sections of this paper, the
many-sorted nature of \FO{} is paramount to the algorithms presented therein.

\begin{remark*}
  In the case of \textsc{ForcLift} and its extensions, support for a formula as
  valid input does not imply that the algorithm can compile the formula into a
  circuit or graph suitable for lifted model counting. However, it is known that
  \textsc{ForcLift} compilation is guaranteed to succeed on any \FO{} formula
  without constants and with at most two
  variables~\cite{DBLP:conf/nips/Broeck11,DBLP:conf/kr/BroeckMD14}.
\end{remark*}

Compared to \FO{}, \Ctwo{} and \UFO{} lack support for constants, the equality
predicate, multiple domains, and formulas with more than two variables. The
advantage that \Ctwo{} brings over \FO{} is the inclusion of \emph{counting
  quantifiers}. That is, alongside $\forall$ and $\exists$, \Ctwo{} supports
$\exists^{=k}$, $\exists^{\le k}$, and $\exists^{\ge k}$ for any positive
integer $k$. For example, $\exists^{=1} x\text{. }\phi(x)$ means that there
exists \emph{exactly one} $x$ such that $\phi(x)$, and $\exists^{\le 2} x\text{.
}\phi(x)$ means that there exist \emph{at most two} such $x$. \UFO{}, on the
other hand, does not support any existential quantifiers but instead
incorporates \emph{(equality) cardinality constraints}. For example, $|P| = 3$
constrains all models to have \emph{precisely three positive literals with the
  predicate $P$}.

\begin{definition}[Model]\label{def:model}
  Let $\phi$ be a formula in \FO{}. For each predicate $P/n$ in $\phi$, let
  ${(\Delta_{i}^{P})}_{i=1}^{n}$ be a list of the corresponding domains. Let
  $\sigma$ be a map from the domains of $\phi$ to their interpretations as sets
  such that the sets are pairwise disjoint, and the constants in $\phi$ are
  included in the corresponding domains. A \emph{structure} of $\phi$ is a set
  $M$ of ground literals defined by adding to $M$ either $P(\mathbf{t})$ or
  $\neg P(\mathbf{t})$ for every predicate $P/n$ in $\phi$ and $n$-tuple
  $\mathbf{t} \in \prod_{i=1}^{n} \sigma(\Delta_{i}^{P})$. A structure is a
  \emph{model} if it satisfies $\phi$.
\end{definition}
% TODO: Page 2, Definition 1 - ”A structure is a model if it satisfies ϕ” - do you mean that it makes ϕ valid?

% (In practice, we typically only specify the size of each domain.)

\begin{remark*}
  The distinctness of domains is important in two ways. First, in terms of
  expressiveness, a clause such as $\forall x \in \Delta\text{. }P(x, x)$ is
  valid if predicate $P$ is defined over two copies of the same domain and
  invalid otherwise. Second, having more distinct domains makes the problem more
  decomposable for the FOKC algorithm. With distinct domains, the algorithm can
  make assumptions or deductions about, e.g., the first domain of predicate $P$
  without worrying how (or if) they apply to the second domain.
\end{remark*}

While this work focuses on FOMC, we still define the weighted variant of the
problem as Skolemization relies on weights even for unweighted FOMC.
% TODO: Even though we are evaluating the algorithms on FOMC benchmarks, for
% sentences with existential quantifiers, computing FOMC using Gantry requires
% the use of WFOMC. For such sentences, Skolemization introduces predicates with
% non-unary weights that must be accounted for to compute the correct model
% count.

\begin{definition}[WFOMC instance]\label{def:instance}
  A \emph{WFOMC instance} comprises: a formula $\phi$ in \FO{}, two (rational)
  \emph{weights} $w^{+}(P)$ and $w^{-}(P)$ assigned to each predicate $P$ in
  $\phi$, and $\sigma$ as described in \cref{def:model}. Unless specified
  otherwise, we assume all weights to be equal to 1.
\end{definition}

\begin{definition}[WFOMC~\cite{DBLP:conf/ijcai/BroeckTMDR11}]
  Given a WFOMC instance $(\phi, w^{+}, w^{-}, \sigma)$ as in
  \cref{def:instance}, the \emph{(symmetric) weighted first-order model count}
  (WFOMC) of $\phi$ is
  \begin{equation}\label{eq:wfomc}
    \sum_{M \models \phi} \prod_{P(\mathbf{t}) \in M} w^{+}(P) \prod_{\neg P(\mathbf{t}) \in M} w^{-}(P),
  \end{equation}
  where the sum is over all models of $\phi$.
\end{definition}

\begin{example}[Counting functions]\label{example:functions}
  To define predicate $P$ as a function from a domain $\Delta$ to itself, in
  \Ctwo{} one would write $\forall x \in \Delta\text{.
  }\exists^{=1} y \in \Delta\text{. }P(x, y)$. In \UFO{}, the same could be
  written as
  \begin{equation}\label[formula]{eq:functions1}
    (\forall x, y \in \Delta\text{. }S(x) \lor \neg P(x, y)) \land (|P| = |\Delta|),
  \end{equation}
  where $w^{-}(S) = -1$. Although \cref{eq:functions1} has more models compared
  to its counterpart in \Ctwo{}, the negative weight $w^{-}(S) = -1$ makes some
  of the terms in \cref{eq:wfomc} cancel out.

  Equivalently, in \FO{} we would write
  \begin{equation}\label[formula]{eq:fo}
    \begin{gathered}
      (\forall x \in \Gamma\text{. }\exists y \in \Delta\text{. }P(x, y)) \land (\forall x \in \Gamma\text{. }\forall y, z \in \Delta\text{. }P(x, y) \land P(x, z) \Rightarrow y = z).
    \end{gathered}
  \end{equation}
  The first clause asserts that each $x$ must have at least one corresponding
  $y$, while the second statement adds the condition that if $x$ is mapped to
  both $y$ and $z$, then $y$ must equal $z$. It is important to note that
  \cref{eq:fo} is written with two domains instead of just one. However, we can
  still determine the correct number of functions by assuming that the sizes of
  $\Gamma$ and $\Delta$ are equal. This formulation, as observed by Dilkas and
  Belle~\cite{DBLP:conf/kr/DilkasB23}, can prove beneficial in enabling FOKC
  algorithms to find efficient solutions.
\end{example}

\subsection{Algebra}\label{sec:algebra}

We write $\expr{}$ for an arbitrary algebraic expression. In the context of
algebra, a \emph{constant} is a non-negative integer. Likewise, a
\emph{variable} can either be a parameter of a function or a variable introduced
through summation, such as $i$ in the expression $\sum_{i=1}^{n} \expr$. A
\emph{function call} is $f(x_{1}, \dots, x_{n})$ (or $f(\mathbf{x})$ for short),
where $f$ is an $n$-ary function, and each $x_{i}$ is an algebraic expression
consisting of variables and constants. A (function) \emph{signature} is function
call that contains only variables. An \emph{equation} is
$f(\mathbf{x}) = \expr{}$, where $f(\mathbf{x})$ is a signature.

\begin{definition}[Base case]\label{def:basecase}
  Let $f(\mathbf{x})$ be a function call where each $x_{i}$ is either a constant
  or a variable. Then function call $f(\mathbf{y})$ is a \emph{base case} of
  $f(\mathbf{x})$ if $f(\mathbf{y}) = f(\mathbf{x})\sigma$, where $\sigma$ is a
  substitution that replaces one or more $x_{i}$ with a constant.
\end{definition}

\begin{example}
  In equation $f(m, n) = f(m-1, n) + nf(m-1, n-1)$, the only constant is $1$,
  and the variables are $m$ and $n$. The equation contains three function calls:
  one on the left-hand side, and two on the right-hand side. The function call
  on the left-hand side is a signature. Function calls such as $f(4, n)$,
  $f(m, 0)$, and $f(8, 1)$ are all considered base cases of $f(m, n)$ (only some
  of which are useful).
\end{example}

\section{Technical Contributions}\label{sec:main}

% TODO: The algorithm’s recursive nature and its interaction with CRANE could be
% explained more clearly

% TODO: more emphasis on the motivation for each part of GANTRY (e.g., how
% FindBaseCases addresses key issues in CRANE) would add depth to the
% contribution.

% TODO: Section 3: you seem to use "equation" and "function" interchangeably

% TODO: this section "would benefit from cleaner reasoning"

% TODO: this section should be expanded by 1 page ("a clear discussion of the
% innovation aspect and technical parts")

\begin{figure*}[t]
  \centering
  \begin{tikzpicture}
    \node[anchor=west] at (-1, 0) (formula) {$\phi$};
    \node[draw,rounded rectangle] at (3, 0) (compilewithbasecases) {\CompileWithBaseCases};
    \node[draw,rounded rectangle] at (9, 0) (compilation) {Compile to C++};

    \node[draw,rounded rectangle,dashed] at (9, -3) (cpp) {C++ code};
    \node[anchor=west] at (-1, -3) (sizes) {Domain sizes};
    \node at (12, -3) (count) {Answer};

    \node[draw,rounded rectangle] at (3, -2) (findbasecases) {\FindBaseCases};
    \node[draw,rounded rectangle,left = 0.1cm of findbasecases] (crane) {\Compile};
    \node[draw,rounded rectangle,right = 0.1cm of findbasecases] (propagate) {\Propagate};
    \node[draw,rounded rectangle,right = 0.1cm of propagate] (simplify) {\Simplify};

    \node[draw,fit={(compilewithbasecases) (compilation) (crane) (findbasecases) (propagate)},inner ysep=7pt,yshift=5pt] {};
    \node at (0.7, 0.5) {\Cranetwo};

    \draw[-Latex] (formula) -- (compilewithbasecases);
    \draw[-Latex] (compilewithbasecases) -- node[above] {$\mathcal{E}$} (compilation);
    \draw[-Latex] (compilation) -- (cpp);
    \draw[-Latex] (sizes) -- (cpp);
    \draw[-Latex] (cpp) -- (count);

    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,left] {uses} (crane);
    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,left] {uses} (findbasecases);
    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,left] {uses} (propagate);
    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,right] {uses} (simplify);
  \end{tikzpicture}
  \caption[]{The outline of using \Cranetwo{} to compute the model count of a
    formula $\phi$. First, the formula is compiled into a set of equations,
    which are then used to create a C++ program. This program can be executed
    with different command line arguments to calculate the model count of $\phi$
    for different domain sizes. To accomplish this, the \CompileWithBaseCases
    function makes use of the FOKC algorithm of \textsc{Crane}, algebraic
    simplification techniques (denoted as \Simplify), and two other auxiliary
    procedures. }\label{fig:overview}
\end{figure*}

\Cref{fig:overview} provides an overview of \Cranetwo{}'s workflow.
\Cref{sec:completing} describes the main algorithm for completing the
definitions of recursive functions with a sufficient set of base cases.
\Cref{sec:identifying,sec:propagating} describe subsidiary algorithms for
constructing a set of base cases and their corresponding logical formulas.
\Cref{sec:smoothing} explains the post-processing techniques for ensuring
accurate model counting. Additionally, \cref{sec:cpp} explains the process of
compiling function definitions into C++ code, greatly expanding upon the range
of formulas that could previously be handled by similar
approaches~\cite{DBLP:conf/kr/KazemiP16}.

\subsection{Completing the Definitions of Functions}\label{sec:completing}

Before describing the main contribution of this work, let us review the
essential aspects of FOKC as realised by \textsc{Crane}. The input formula is
compiled into: set $\mathcal{E}$ of equations, map $\mathcal{F}$ from function
names to formulas, and map $\mathcal{D}$ from function names and argument
indices to domains. $\mathcal{E}$ can contain any number of functions, one of
which (denoted by $f$) represents the solution to the FOMC problem. To compute
the FOMC for particular domain sizes, $f$ must be evaluated with those domain
sizes as arguments. $\mathcal{D}$ records this correspondence between function
arguments and domains.

\begin{algorithm}[t]
  \caption{\protect\CompileWithBaseCases{$\phi$}}\label{alg:compilewithbasecases}
  \KwIn{formula $\phi$}
  \KwOut{set $\mathcal{E}$ of equations}
  $(\mathcal{E}, \mathcal{F}, \mathcal{D}) \gets \Compile{$\phi$}$\;
  $\mathcal{E} \gets \Simplify{$\mathcal{E}$}$\;\label{line:second}
  \ForEach{base case $f(\mathbf{x}) \in \FindBaseCases{$\mathcal{E}$}$}{
    $\psi \gets \mathcal{F}(f)$\;
    \lForEach{index $i$ such that $x_{i} \in \mathbb{N}_{0}$}{$\psi \gets \Propagate{$\psi$, $\mathcal{D}(f, i)$, $x_i$}$}
    $\mathcal{E} \gets \mathcal{E} \cup \CompileWithBaseCases{$\psi$}$\;\label{line:final}
  }
\end{algorithm}

\Cref{alg:compilewithbasecases} presents our overall approach for compiling a
formula into equations that include the necessary base cases. To begin, we use
the FOKC algorithm of the original \textsc{Crane} to compile the formula into
the three components: $\mathcal{E}$, $\mathcal{F}$, and $\mathcal{D}$. After
some algebraic simplification, $\mathcal{E}$ is passed to the \FindBaseCases
procedure (see \cref{sec:identifying}). For each base case $f(\mathbf{x})$, we
retrieve the logical formula $\mathcal{F}(f)$ associated with the function name
$f$ and simplify it using the \Propagate procedure (explained in detail in
\cref{sec:propagating}). We do this by iterating over all indices of
$\mathbf{x}$, where $x_{i}$ is a constant, and using \Propagate to simplify
$\psi$ by assuming that domain $\mathcal{D}(f, i)$ has size $x_{i}$. Finally, on
\autoref{line:final}, \CompileWithBaseCases recurses on these simplified
formulas and adds the resulting base case equations to $\mathcal{E}$.
\Cref{example:overall} below provides more detail.

\begin{remark*}
  Although \CompileWithBaseCases starts with a call to \textsc{Crane}, the
  proposed algorithm is not just a post-processing step for FOKC because
  \cref{alg:compilewithbasecases} is recursive and can issue more calls to
  \textsc{Crane} on various derived formulas.
\end{remark*}

% TODO: move this example right after the definition of WFOMC (or near the
% definition of a model)
\begin{example}[Counting bijections]\label{example:overall}
  Consider the following formula (previously examined by Dilkas and
  Belle~\cite{DBLP:conf/kr/DilkasB23}) that defines predicate $P$ as a bijection
  between two sets $\Gamma$ and $\Delta$:
  \[
    \begin{gathered}
      (\forall x \in \Gamma\text{. }\exists y \in \Delta\text{. }P(x, y))\land{}\\
      (\forall y \in \Delta\text{. }\exists x \in \Gamma\text{. }P(x, y))\land{}\\
      (\forall x \in \Gamma\text{. }\forall y, z \in \Delta\text{. }P(x, y) \land P(x, z) \Rightarrow y = z)\land{}\\
      (\forall x, z \in \Gamma\text{. }\forall y \in \Delta\text{. }P(x, y) \land P(z, y) \Rightarrow x = z).
    \end{gathered}
  \]
  We specifically examine the first solution returned by \Cranetwo{} for this
  formula.

  After \autoref{line:second}, we have
  \begin{align*}
    \mathcal{E} &= \left\{\,\begin{aligned}f(m, n) &= \sum_{l=0}^{n} \binom{n}{l}{(-1)}^{n-l}g(l, m),\\ g(l, m) &= g(l-1, m) + mg(l-1, m-1)\end{aligned}\,\right\};\\
    \mathcal{D} &= \{\, (f, 1) \mapsto \Gamma, (f, 2) \mapsto \Delta, (g, 1) \mapsto \Delta^{\top}, (g, 2) \mapsto \Gamma \,\},
  \end{align*}
  where $\Delta^{\top}$ is a new domain. (We omit the definition of
  $\mathcal{F}$ as the formulas can get a bit verbose.) Then \FindBaseCases
  identifies two base cases: $g(0, m)$ and $g(l, 0)$. In both cases,
  \CompileWithBaseCases recurses on the formula $\mathcal{F}(g)$ simplified by
  assuming that one of the domains is empty. In the first case, we recurse on
  the formula $\forall x \in \Gamma\text{. }S(x) \lor \neg S(x)$, where $S$ is a
  predicate introduced by Skolemization with weights $w^{+}(S) = 1$ and
  $w^{-}(S) = -1$. Hence, we obtain the base case $g(0, m) = 0^{m}$. In the case
  of $g(l, 0)$, \Propagate{$\psi$, $\Gamma$, $0$} returns an empty formula,
  resulting in $g(l, 0) = 1$.
\end{example}

It is worth noting that these base cases overlap when $l = m = 0$ but remain
consistent since $0^{0} = 1$. Generally, let $\phi$ be a formula with two
domains $\Gamma$ and $\Delta$, and let $n, m \in \mathbb{N}_{0}$. Then the FOMC
of \Propagate{$\phi$, $\Delta$, $n$} assuming $|\Gamma| = m$ is the same as the
FOMC of \Propagate{$\phi$, $\Gamma$, $m$} assuming $|\Delta| = n$.

Finally, the main responsibility of the \Simplify procedure is to handle the
algebraic pattern $\sum_{m=0}^{n}[a \le m \le b] f(m)$. Here: $n$ is a variable,
$a, b \in \mathbb{N}_{0}$ are constants, and $f$ is an expression that may
depend on $m$. Additionally, $[a \le m \le b] = \begin{cases}
  1 & \text{if $a \le m \le b$} \\
  0 & \text{otherwise}
\end{cases}$.
\Simplify transforms this pattern into
$f(a) + f(a+1) + \cdots + f(\min\{\, n, b \,\})$. For instance, in the case of
\cref{example:overall}, \Simplify transforms
$g(l, m) = \sum_{k=0}^{m}[0 \le k \le 1]\binom{m}{k}g(l-1, m-k)$ into
$g(l, m) = g(l-1, m) + mg(l-1, m-1)$.

\subsection{Identifying a Sufficient Set of Base Cases}\label{sec:identifying}
% TODO: prove correctness?

\begin{algorithm}[t]
  \caption{\protect\FindBaseCases{$\mathcal{E}$}}\label{alg:findbasecases}
  \KwIn{set $\mathcal{E}$ of equations}
  \KwOut{set $\mathcal{B}$ of base cases}

  $\mathcal{B} \gets \emptyset$\;
  \ForEach{function call $f(\mathbf{y})$ on the right-hand side of an equation in $\mathcal{E}$}{
    $\mathbf{x} \gets \text{the parameters of $f$ in its definition}$\;
    \ForEach{$y_{i} \in \mathbf{y}$} {
      \lIf{$y_{i} \in \mathbb{N}_{0}$}{$\mathcal{B} \gets \mathcal{B} \cup \{\, f(\mathbf{x})[x_{i} \mapsto y_{i}] \,\}$}
      \ElseIf{$y_{i} = x_{i} - c_{i}$ for some $c_{i} \in \mathbb{N}_{0}$}{
        \lFor{$j \gets 0$ \KwTo $c_{i} - 1$}{$\mathcal{B} \gets \mathcal{B} \cup \{\, f(\mathbf{x})[x_{i} \mapsto j] \,\}$}
      }
    }
  }
\end{algorithm}
% (later, let's not bother yet): replace x_i-c_i on Line 7 of Algorithm 2 with a
% generalisation of x_i that can be an arbitrary summation/subtraction of domain
% sizes (propagating this change to the rest of the paper, particularly
% Assumption 1, the proof of Lemma 1)

\Cref{alg:findbasecases} summarises the implementation of \FindBaseCases. It
considers two types of arguments when a function $f$ calls itself recursively:
constants and arguments of the form $x_{i} - c_{i}$. Here, $c_{i}$ is a
constant, and $x_{i}$ is the $i$-th argument of the signature of $f$. When the
argument is a constant $c_{i}$, a base case with $c_{i}$ is added. In the second
case, a base case is added for each constant from $0$ up to (but not including)
$c_{i}$.

\begin{example}
  Consider the recursive function $g$ from \cref{example:overall}.
  \FindBaseCases iterates over two function calls: $g(l-1, m)$ and
  $g(l-1, m-1)$. The former produces the base case $g(0, m)$, while the latter
  produces both $g(0, m)$ and $g(l, 0)$.
\end{example}

It can be shown that the base cases identified by \FindBaseCases are sufficient
for the algorithm to terminate.\footnote{Note that characterising the
  fine-grained complexity of the solutions found by \Cranetwo{} or other FOMC
  algorithms is an emerging area of research. These questions have been
  partially addressed in previous
  work~\cite{DBLP:conf/kr/DilkasB23,tóth2024complexityweightedfirstordermodel}
  and are orthogonal to the goals of this section.} For the remainder of this
section, let $\mathcal{E}$ denote the equations returned by
\CompileWithBaseCases.

\begin{theorem}[Termination]\label{thm:halting}
  Let $f$ be an $n$-ary function in $\mathcal{E}$ and
  $\mathbf{x} \in \mathbb{N}_{0}^{n}$. Then the evaluation of $f(\mathbf{x})$
  terminates.
\end{theorem}

We prove \cref{thm:halting} using double induction. First, we apply induction to
the number of functions in $\mathcal{E}$. Then, we use induction on the arity of
the `last' function in $\mathcal{E}$ according to some topological ordering. We
begin with a few observations that stem from
previous~\cite{DBLP:conf/kr/DilkasB23,DBLP:conf/ijcai/BroeckTMDR11} and this
work. Let $\mathcal{E}$ represent the equations returned by
\CompileWithBaseCases.

\begin{observation}\label{assumption1}
  For each function $f$, there is precisely one equation $e \in \mathcal{E}$
  with $f(\mathbf{x})$ on the left-hand side where all $x_{i}$'s are variables
  (i.e., $e$ is not a base case). We refer to $e$ as the \emph{definition} of
  $f$.
\end{observation}

\begin{observation}\label{assumption2}
  There is a \emph{topological ordering} of all functions ${(f_{i})}_{i}$ in
  $\mathcal{E}$ such that equations in $\mathcal{E}$ with $f_{i}$ on the
  left-hand side do not contain function calls to $f_{j}$ with $j > i$. This
  condition prevents mutual recursion and other cyclic scenarios.
\end{observation}

\begin{observation}\label{assumption3}
  For every equation $(f(\mathbf{x}) = \expr) \in \mathcal{E}$, the evaluation
  of $\expr$ terminates when provided with the values of all relevant function
  calls.
\end{observation}

\begin{corollary}\label{fact}
  If $f$ is a non-recursive function with no function calls on the right-hand
  side of its definition, then the evaluation of any function call
  $f(\mathbf{x})$ terminates.
\end{corollary}

\begin{observation}\label{fact2}
  For any equation $f(\mathbf{x}) = \expr{}$, if $\mathbf{x}$ contains only
  constants, then $\expr{}$ cannot include any function calls to $f$.
\end{observation}

Additionally, we introduce an assumption about the structure of recursion.

\begin{assumption}\label{assumption4}
  For every equation $(f(\mathbf{x}) = \expr) \in \mathcal{E}$, every recursive
  function call $f(\mathbf{y}) \in \expr$ satisfies the
  following:
  \begin{itemize}
    \item Each $y_{i}$ is either $x_{i} - c_{i}$ or $c_{i}$ for some constant
          $c_{i}$.
    \item There exists $i$ such that $y_{i} = x_{i} - c_{i}$ for some
          $c_{i} > 0$.
  \end{itemize}
\end{assumption}

Finally, we assume a particular order of evaluation for function calls using the
equations in $\mathcal{E}$. Specifically, we assume that base cases are
considered before the recursive definition. The exact order in which base cases
are considered is immaterial.

\begin{assumption}
  When multiple equations in $\mathcal{E}$ match a function call
  $f(\mathbf{x})$, preference is given to an equation with the most constants on
  its left-hand side.
\end{assumption}

With the observations and assumptions mentioned above, we are ready to prove
\cref{thm:halting}. For readability, we divide the proof into several lemmas of
increasing generality.

\begin{lemma}\label{lemma:oneunary}
  Assume that $\mathcal{E}$ consists of just \emph{one unary} function $f$. Then
  the evaluation of a function call $f(x)$ terminates for any
  $x \in \mathbb{N}_{0}$.
\end{lemma}
\begin{proof}
  If $f(x)$ is captured by a base case, then its evaluation terminates by
  \cref{fact,fact2}. If $f$ is not recursive, the evaluation of
  $f(x)$ terminates by \cref{fact}.

  Otherwise, let $f(y)$ be an arbitrary function call on the right-hand side of
  the definition of $f(x)$. If $y$ is a constant, then there is a base case for
  $f(y)$. Otherwise, let $y = x - c$ for some $c > 0$. Then there exists
  $k \in \mathbb{N}_{0}$ such that $0 \le x - kc \le c-1$. So, after $k$
  iterations, the sequence of function calls $f(x), f(x-c), f(x-2c),\dots$ will
  be captured by the base case $f(x \mod c)$.
\end{proof}

\begin{lemma}\label{lemma:onefunction}
  Generalising \cref{lemma:oneunary}, let $\mathcal{E}$ be a set of equations
  for \emph{one} $n$-ary function $f$ for some $n \ge 1$. Then the evaluation of
  $f(\mathbf{x})$ terminates for any $\mathbf{x} \in \mathbb{N}_{0}^{n}$.
\end{lemma}
\begin{proof}
  If $f$ is non-recursive, the evaluation of $f(\mathbf{x})$ terminates by
  previous arguments. We proceed by induction on $n$, with the base case of
  $n=1$ handled by \cref{lemma:oneunary}. Assume that $n > 1$. Any base case of
  $f$ can be seen as a function of arity $n-1$, since one of the parameters is
  fixed. Thus, the evaluation of any base case terminates by the inductive
  hypothesis. It remains to show that the evaluation of the recursive equation
  for $f$ terminates, but that follows from \cref{assumption3}.
\end{proof}

\begin{proof}[Proof of \cref{thm:halting}]
  We proceed by induction on the number of functions $n$. The base case of $n=1$
  is handled by \cref{lemma:onefunction}. Let ${(f_{i})}_{i=1}^{n}$ be some
  topological ordering of these $n > 1$ functions. If $f = f_{j}$ for $j < n$,
  then the evaluation of $f(\mathbf{x})$ terminates by the inductive hypothesis
  since $f_{j}$ cannot call $f_{n}$ by \cref{assumption2}. Using the inductive
  hypothesis that all function calls to $f_{j}$ (with $j < n$) terminate, the
  proof proceeds similarly to the Proof of \cref{lemma:onefunction}.
\end{proof}

\subsection{Propagating Domain Size Assumptions}\label{sec:propagating}

\begin{algorithm}[t]
  \caption{\protect\Propagate{$\phi$, $\Delta$, $n$}}\label{alg:propagate}
  \KwIn{formula $\phi$, domain $\Delta$, $n \in \mathbb{N}_{0}$}
  \KwOut{formula $\phi'$}
  $\phi' \gets \emptyset$\;
  \uIf{$n = 0$}{
    \ForEach{clause $C \in \phi$}{
      \lIf{$\Delta \not\in \Doms(C)$}{$\phi' \gets \phi' \cup \{\, C \,\}$}
      \Else{
        $C' \gets \{\, l \in C \mid \Delta \not\in \Doms(l) \,\}$\;
        \If{$C' \ne \emptyset$}{\label{line:presmoothing}
          $l \gets \text{an arbitrary literal in } C'$\;\label{line:smoothing1}
          $\phi' \gets \phi' \cup \{\, C' \cup \{\, \neg l \,\} \,\} $\;\label{line:smoothing2}
        }
      }
    }
  }
  \Else{
    $D \gets \text{a set of $n$ new constants in $\Delta$}$\;
    \ForEach{clause $C \in \phi$}{
      ${(x_{i})}_{i=1}^{m} \gets \text{the variables in $C$ with domain $\Delta$}$\;
      \lIf{$m = 0$}{$\phi' \gets \phi' \cup \{\, C \,\}$}
      \lElse{$\phi' \gets \phi' \cup \{\, C[x_{1} \mapsto c_{1}, \dots, x_{m} \mapsto c_{m}] \mid {(c_{i})}_{i=1}^{m} \in D^{m} \,\}$}
    }
  }
\end{algorithm}

\Cref{alg:propagate}, called \Propagate, modifies the formula $\phi$ based on
the assumption that $|\Delta| = n$. When $n=0$, some clauses become vacuously
satisfied and can be removed. When $n > 0$, partial grounding is performed by
replacing all variables quantified over $\Delta$ with constants. (None of the
formulas examined in this work had $n > 1$.) \Cref{alg:propagate} handles these
two cases separately. For a literal or a clause $C$, the set of corresponding
domains is denoted as $\Doms(C)$.

% NOTE: keep this enumerate
In the case of $n = 0$, there are three types of clauses to consider:
\begin{enumerate}
  \item those that do not mention $\Delta$,\label[type]{type1}
  \item those in which every literal contains variables quantified over
  $\Delta$, and\label[type]{type2}
  \item those that have some literals with variables quantified over $\Delta$
  and some without.\label[type]{type3}
\end{enumerate}
Clauses of \cref{type1} are transferred to the new formula $\phi'$ without any
changes. For clauses of \cref{type2}, $C'$ is empty, so these clauses are
filtered out. As for clauses of \cref{type3}, a new kind of smoothing is
performed, which will be explained in \cref{sec:smoothing}.

In the case of $n>0$, $n$ new constants are introduced. Let $C$ be an arbitrary
clause in $\phi$, and let $m \in \mathbb{N}_{0}$ be the number of variables in
$C$ quantified over $\Delta$. If $m=0$, $C$ is added directly to $\phi'$.
Otherwise, a clause is added to $\phi'$ for every possible combination of
replacing the $m$ variables in $C$ with the $n$ new constants.

\begin{example}
  Let $C \equiv \forall x \in \Gamma\text{. }\forall y, z \in \Delta\text{.
  } \neg P(x, y) \lor \neg P(x, z) \lor y=z$. Then
  $\Doms(C) = \Doms(\neg P(x, y)) = \Doms(\neg P(x, z)) = \{\, \Gamma, \Delta \,\}$,
  and $\Doms(y=z) = \{\, \Delta \,\}$. A call to \Propagate{$\{\, C \,\}$,
    $\Delta$, $3$} would result in the following formula with nine clauses:
  \begin{align*}
    (\forall x \in \Gamma\text{. }\neg P(x, c_{1}) \lor& \neg P(x, c_{1}) \lor c_{1}=c_{1})\land{}\\
    (\forall x \in \Gamma\text{. }\neg P(x, c_{1}) \lor& \neg P(x, c_{2}) \lor c_{1}=c_{2})\land{}\\
    \vdots&\\
    (\forall x \in \Gamma\text{. }\neg P(x, c_{3}) \lor& \neg P(x, c_{3}) \lor c_{3}=c_{3}).
  \end{align*}
  Here, $c_{1}$, $c_{2}$, and $c_{3}$ are the new constants.
\end{example}

\subsection{Smoothing the Base Cases}\label{sec:smoothing}

\emph{Smoothing} modifies a circuit to reintroduce eliminated atoms, ensuring
the correct model
count~\cite{darwiche2001tractable,DBLP:conf/ijcai/BroeckTMDR11}. In this
section, we describe a similar process performed on
lines~\ref{line:presmoothing}--\ref{line:smoothing2} of \cref{alg:propagate}.
Line~\ref{line:presmoothing} checks if smoothing is necessary, and
lines~\ref{line:smoothing1} and~\ref{line:smoothing2} execute it. If the
condition on \autoref{line:presmoothing} is not satisfied, the clause is not
smoothed but omitted.

Suppose \Propagate is called with arguments $(\phi, \Delta, 0)$, i.e., we are
simplifying the formula $\phi$ by assuming that the domain $\Delta$ is empty.
Informally, if there is a predicate $P$ in $\phi$ unrelated to $\Delta$,
smoothing preserves all occurrences of $P$ even if all clauses with $P$ become
vacuously satisfied.

\begin{example}\label{example:basecasesmoothing}
  Let $\phi$ be
  \begin{align}
    (\forall x \in \Delta\text{. }\forall y, z \in \Gamma&\text{. }Q(x) \lor P(y, z))\land{}\label[clause]{eq:example1}\\
    (\forall y, z \in \Gamma'&\text{. }P(y, z))\label[clause]{eq:example2},
  \end{align}
  where $\Gamma' \subseteq \Gamma$ is a domain introduced by a compilation rule.
  It should be noted that $P$, as a relation, is a subset of
  $\Gamma \times \Gamma$.

  Now, let us reason manually about the model count of $\phi$ when
  $\Delta = \emptyset$. Predicate $Q$ can only take one value, $Q = \emptyset$.
  The value of $P$ is fixed over $\Gamma' \times \Gamma'$ by \cref{eq:example2},
  but it can vary freely over
  $(\Gamma \times \Gamma) \setminus (\Gamma' \times \Gamma')$ since
  \cref{eq:example1} is vacuously satisfied by all structures. Therefore, the
  correct FOMC should be $2^{|\Gamma|^2 - |\Gamma'|^2}$. However, without
  \autoref{line:smoothing2}, \Propagate would simplify $\phi$ to
  $\forall y, z \in \Gamma'\text{. }P(y, z)$. In this case, $P$ is a subset of
  $\Gamma' \times \Gamma'$. This simplified formula has only one model:
  $\{\, P(y, z) \mid y, z \in \Gamma' \,\}$. By including
  \autoref{line:smoothing2}, \Propagate transforms $\phi$ to
  \[
    (\forall y, z \in \Gamma\text{. }P(y, z) \lor \neg P(y, z)) \land (\forall y, z \in \Gamma'\text{. }P(y, z)),
  \]
  which retains the correct model count.
\end{example}

It is worth mentioning that the choice of $l$ on \autoref{line:smoothing1} of
\cref{alg:propagate} is inconsequential because any choice achieves the same
goal: constructing a tautological clause that retains the literals in $C'$.

\subsection{Generating C++ Code}\label{sec:cpp}
% TODO (must): expand this section
% TODO: The purpose of C++ code generation is to turn mathematical equations into executable code.

In this section, we will describe the final step of \Cranetwo{} as outlined in
\cref{fig:overview}. This step involves translating the set of equations
$\mathcal{E}$ into C++ code. The resulting C++ program can then be compiled and
executed with different command-line arguments to compute the model count of the
formula for various domain sizes.

Each equation in $\mathcal{E}$ is compiled into a C++ function, along with a
separate cache for memoisation. Let us consider an arbitrary equation
$e = (f(\mathbf{x}) = \expr{}) \in \mathcal{E}$, and let
$\mathbf{c} \in \mathbb{N}_{0}^{n}$ represent the arguments of the corresponding
C++ function. The implementation of $e$ consists of three parts. First, we check
if $\mathbf{c}$ is already present in the cache of $e$. If it is, we simply
return the cached value. Second, for each base case $f(\mathbf{y})$ of
$f(\mathbf{x})$ (as defined in \cref{def:basecase}), we check if $\mathbf{c}$
\emph{matches} $\mathbf{y}$, i.e., $c_{i} = y_{i}$ whenever
$y_{i} \in \mathbb{N}_{0}$. If this condition is satisfied, $\mathbf{c}$ is
redirected to the C++ function that corresponds to the definition of the base
case $f(\mathbf{y})$. Finally, if none of the above cases apply, we evaluate
$\mathbf{c}$ based on the expression $\expr{}$, store the result in the cache,
and return it.

\section{Experimental Evaluation}\label{sec:experiments}

% 1. Introduction
% Objective: Briefly state the goals of the experiments.
% Overview: Summarize the structure of the section.

% 2. Experimental Setup

% Baselines: List and describe the baseline methods or systems used for
% comparison.

% TODO Experiments could be expanded by 1 page ("a more thorough and independent
% practical assessment")

% TODO: this section "would benefit from cleaner reasoning"

% TODO: The difference between Gantry-Greedy and Gantry-BFS is in how the
% algorithm chooses which compilation rule to apply to a formula. The former
% uses greedy search: there is a list of rules, and the first applicable rule is
% the one that gets used, disregarding all the others. The latter uses a
% combination of greedy and breadth-first search (BFS). That is, each
% compilation rule is identified as either greedy or non-greedy. Greedy rules
% are applied as soon as possible at any stage of the compilation process. BFS
% is executed over all applicable non-greedy rules, identifying the solution
% that can be constructed using the smallest number of such rules.

Our empirical evaluation sought to compare the runtime performance of
{\Cranetwo} with the current state of the art, namely \textsc{FastWFOMC} and
\textsc{ForcLift}. It is worth remarking that \textsc{ForcLift} does not support
arbitrary precision, and returns error for cases that requires arbitrary
precision reasoning. Our experiments involve two versions of \Cranetwo{}:
\Cranegreedy{} and \Cranebfs{}. Like its predecessor, \Cranetwo{} has two modes
for applying compilation rules to formulas: one that uses a greedy search
algorithm similar to \textsc{ForcLift} and another that combines greedy and
breadth-first search.

The experiments were conducted using an Intel Skylake \SI{2.4}{\giga\hertz} CPU
with \SI{188}{\gibi\byte} of memory and CentOS~7. C++ programs were compiled
using the Intel C++ Compiler 2020u4. \textsc{FastWFOMC} ran on Julia~1.10.4,
while the other algorithms were executed on the Java Virtual Machine 1.8.0\_201.

% It would not make sense to include the original \textsc{Crane} algorithm in
% the experiments or evaluate \Cranetwo{} without the C++ code generation
% described in \cref{sec:cpp}. Indeed, these algorithms can only produce
% mathematical definitions of functions without evaluating them.

% While greedy search is more efficient (in terms of being able to handle larger
% formulas), it is a heuristic that can miss some solutions.

% Datasets: Provide details about the datasets used in the experiments,
% including size, source, and any preprocessing steps.

\subsection{Benchmarks}
% TODO: more benchmarks from NOT my work
% TODO: make sure it's clear what the 'raw' instances are
% TODO: don't emphasise that the benchmarks come from my previous work

We compare these algorithms using three benchmarks from previous studies. The
first benchmark is the function-counting problem from \cref{example:functions},
previously examined by Dilkas and Belle~\cite{DBLP:conf/kr/DilkasB23}. The
second benchmark is a variant of the well-known `Friends and Smokers' Markov
logic network~\cite{DBLP:conf/aaai/SinglaD08,DBLP:conf/uai/BroeckCD12}. In
\Ctwo{}, \FO{}, and \UFO{}, this problem can be formulated as
\[
  (\forall x,y \in \Delta\text{. } S(x) \land F(x, y) \Rightarrow S(y)) \land (\forall x \in \Delta\text{. }S(x) \Rightarrow C(x))
\]
or, equivalently, in conjunctive normal form as
\[
  (\forall x,y \in \Delta\text{. }S(y) \lor \neg S(x) \lor \neg F(x, y)) \land (\forall x \in \Delta\text{. } C(x) \lor \neg S(x)).
\]
Finally, we include the bijection-counting problem previously utilised by Dilkas
and Belle~\cite{DBLP:conf/kr/DilkasB23}. Its formulation in \FO{} is described
in \cref{example:overall}. The equivalent formula in \Ctwo{} is
\[
  (\forall x \in \Delta\text{. }\exists^{=1} y \in \Delta\text{. }P(x, y)) \land (\forall y \in \Delta\text{. }\exists^{=1} x \in \Delta\text{. }P(x, y)).
\]
Similarly, in \UFO{} the same formula can be written as
\[
  (\forall x, y \in \Delta\text{. }R(x) \lor \neg P(x, y)) \land (\forall x, y \in \Delta\text{. }S(x) \lor \neg P(y, x)) \land (|P| = |\Delta|),
\]
where $w^{-}(R) = w^{-}(S) = -1$.

\begin{figure*}[t]
  \centering
  \includegraphics{plot.pdf}
  \caption{The runtime of the algorithms as a function of the domain size. Note
    that both axes are on a logarithmic scale.}\label{fig:plot}
\end{figure*}
% TODO: shrink/restructure to fit into the margins

%Since \textsc{FastWFOMC} does not support many-sorted logic, our experiments are
%limited to formulas with a single domain. However, many of the counting problems
%used in the experimental evaluation of
%\textsc{Crane}~\cite{DBLP:conf/kr/DilkasB23} become equivalent (in terms of
%generating equivalent integer sequences) when restricted to a single domain.
%Additionally, comparing \Cranetwo{} and \textsc{FastWFOMC} on a broader set of
%problems is challenging because each problem needs to be represented in two
%(quite different) logics: \FO{} and \UFO{}.

The three benchmark families cover a wide range of possibilities. The
`friends' benchmark stands out as it uses multiple predicates and can be
expressed in \FO{} using just two variables without cardinality constraints or
counting quantifiers. The `functions' benchmark, on the other hand, can still be
handled by all the algorithms, but it requires cardinality constraints, counting
quantifiers, or more than two variables. Lastly, the `bijections' benchmark is
an example of a formula that \textsc{FastWFOMC} can handle but \textsc{ForcLift}
cannot.

% Metrics: Define the performance metrics used to evaluate the results (e.g.,
% accuracy, precision, recall, F1-score, runtime).

%A considerable difference between \textsc{ForcLift} and the other two algorithms
%is that \textsc{ForcLift} does not support arbitrary precision whereas the other
%algorithms use the GNU Multiple Precision Arithmetic Library. Thus, when the
%count exceeds finite precision, \textsc{ForcLift} returns $\infty$.

For evaluation purposes, we ran each algorithm on each benchmark using domains
of sizes $2^{1}, 2^{2}, 2^{3}$, and so on, until an algorithm failed to handle a
domain size due to timeout, out of memory error, or out of precision errors.
While we separately measured compilation and inference time, we primarily focus
on total runtime, dominated by the latter.

% Environment: Describe the hardware and software environment (e.g.,
% specifications of the computer, operating system, libraries, and tools used).



% 3. Results and Analysis
% Presentation of Results: Use tables, graphs, and charts to present the experimental results clearly.
% Comparison with Baselines: Compare your method’s results with the baselines.
% Discussion: Analyze and interpret the results, highlighting the strengths and potential weaknesses of your approach.
% Insights: Provide insights or patterns observed from the results.
% Challenges: Discuss any challenges or unexpected outcomes.
% Acknowledgement: Honestly acknowledge any limitations of your experiments or method.

\subsection{Results}

% TODO: On the ’friends’ and ’functions’ benchmarks, ForcLift runs until the
% model count exceeds 231 − 1.

% TODO: We are not aware of any formulas on which Gantry scales worse compared
% to either ForcLift or FastWFOMC. The one advantage that FastWFOMC has over
% Gantry is its support for counting quantifiers.

% TODO: Regarding programming languages and accuracy, we verified that the
% answers match for smaller domain sizes. Also, although written in different
% languages, both Gantry and FastWFOMC use the GNU Multiple Precision Arithmetic
% Library.

\Cref{fig:plot} presents a summary of the experimental results. Only
\textsc{FastWFOMC} and \Cranebfs{} could handle the bijection-counting problem.
For this benchmark, the largest domain sizes these algorithms could accommodate
were \num{64} and \num{4096}, respectively. On the other two benchmarks,
\textsc{ForcLift} had the lowest runtime. However, due to its finite precision,
it only scaled up to domain sizes of \num{16} and \num{128} for `friends' and
`functions', respectively. \textsc{FastWFOMC} outperformed \textsc{ForcLift} in
the case of `friends', but not `functions', as it could handle domains of size
\num{1024} and \num{64}, respectively. Furthermore, both \Cranebfs{} and
\Cranegreedy{} performed similarly on both benchmarks. Similarly to the
`bijections' benchmark, \Cranetwo{} significantly outperformed the other two
algorithms, scaling up to domains of size \num{8192} and \num{67108864},
respectively.

Another aspect of the experimental results that deserves separate discussion is
compilation. Both Julia and Scala use just-in-time (JIT) compilation, which
means that \textsc{FastWFOMC} and \textsc{ForcLift} take longer to run on the
smallest domain size, where most JIT compilation occurs. In the case of
\Cranetwo{}, it is only run once per benchmark, so the JIT compilation time is
included in its overall runtime across all domain sizes. Additionally, while
\textsc{ForcLift}'s compilation is generally faster than that of \Cranetwo{},
neither significantly affects overall runtime. Specifically, \textsc{ForcLift}
compilation typically takes around \SI{0.5}{\second}, while \Cranetwo{}
compilation takes around \SI{2.3}{\second}.

% 8. Conclusion
% Summary: Briefly summarize the key findings from the experimental results.
% Future Work: Suggest directions for future research based on your findings.

Based on our experiments, which algorithm should be used in practice? If the
formula can be handled by \textsc{ForcLift} and the domain sizes are reasonably
small, \textsc{ForcLift} is likely the fastest algorithm. In other situations,
\Cranetwo{} is expected to be significantly more efficient than
\textsc{FastWFOMC} regardless of domain size, provided both algorithms can
handle the formula.

\section{Conclusion and Future Work}\label{sec:conclusion}

In this work, we have presented a scalable automated FOKC-based approach to
FOMC. Our algorithm involves completing the definitions of recursive functions
and subsequently translating all function definitions into C++ code. Empirical
results demonstrate that \Cranetwo{} can scale to larger domain sizes than
\textsc{FastWFOMC} while supporting a wider range of formulas than
\textsc{ForcLift}. The ability to efficiently handle large domain sizes is
particularly crucial in the weighted setting, as illustrated by the `friends'
example discussed in \cref{sec:experiments}, where the model captures complex
social networks with probabilistic relationships. Without this scalability, the
practical usefulness of these models would be limited.

Future directions for research include conducting a comprehensive experimental
comparison of FOMC algorithms to better understand their comparative performance
across various formulas. The capabilities of \Cranetwo{} could also be
characterised theoretically, e.g.\ by proving completeness for specific logic
fragments like \Ctwo{}. Additionally, the efficiency of FOMC algorithms can be
further analysed using fine-grained complexity, which would provide more
detailed insights into the computational demands of different formulas.

\bibliography{paper}

\end{document}
