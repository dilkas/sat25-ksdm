\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{microtype}
\usepackage{mathtools}
\usepackage{forest}
\usepackage{siunitx}
\usepackage{amsfonts}
\usepackage{pifont}
\usepackage[inline]{enumitem}
\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{booktabs}
\usepackage{amsthm}

\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{corollary}{Corollary}
\newtheorem{fact}{Observation}
\newtheorem{lemma}{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\usetikzlibrary{arrows.meta}
\usetikzlibrary{positioning}

\forestset{
  sn edges/.style={for tree={edge={-Latex}}}
}

\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\newcommand{\expr}{\mathtt{expr}}
\newcommand{\Ctwo}{$\mathsf{C}^{2}$}
\newcommand{\FO}{$\mathsf{FO}$}
\newcommand{\UFO}{$\mathsf{UFO}^{2} + \mathsf{CC}$}
\newcommand{\Cranetwo}{\textsc{Crane2}}
\newcommand{\Cranebfs}{\textsc{Crane2-BFS}}
\newcommand{\Cranegreedy}{\textsc{Crane2-Greedy}}

\newcommand{\crefrangeconjunction}{--}
\crefname{line}{line}{lines}
%\crefname{fact}{Observation}{Observations}
\crefname{assumption}{Assumption}{Assumptions}
\crefalias{enumi}{type}
\crefname{type}{Type}{Types}
\creflabelformat{type}{#2\textup{#1}#3}
\crefalias{enumi}{step}
\crefname{step}{Step}{Steps}
\creflabelformat{step}{#2\textup{#1}#3}
\crefalias{clause}{equation}
\crefname{clause}{Clause}{Clauses}
\creflabelformat{clause}{#2\textup{(#1)}#3}
\crefalias{formula}{equation}
\crefname{formula}{Formula}{Formulas}
\creflabelformat{formula}{#2\textup{(#1)}#3}

\DeclareMathOperator{\CR}{CR}
\DeclareMathOperator{\DR}{DR}
\DeclareMathOperator{\Reff}{Ref}
\DeclareMathOperator{\Doms}{Doms}

\SetKwFunction{CompileWithBaseCases}{CompileWithBaseCases}
\SetKwFunction{Compile}{{\normalfont \textsc{Crane}}}
\SetKwFunction{Propagate}{Propagate}
\SetKwFunction{FindBaseCases}{FindBaseCases}
\SetKwFunction{Simplify}{Simplify}

\pdfinfo{
/TemplateVersion (2025.1)
}

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

\title{Towards Practical First-Order Model Counting}
\author{Anonymous Submission}
\affiliations{}

\begin{document}

\maketitle

\begin{abstract}
	First-order model counting (FOMC) is the problem of counting the number of models of a sentence in first-order logic. Since lifted inference techniques rely on reductions to variants of FOMC, the design of scalable methods for FOMC has attracted attention from both theoreticians and practitioners over the past decade. Recently, a new approach based on first-order knowledge compilation was proposed. This approach, called \textsc{crane}, instead of simply providing the final count, generates definitions of (possibly recursive) functions that can be evaluated with different arguments to compute the model count for any domain size. However, this approach is not fully automated, as it requires manual evaluation of the constructed functions. The primary contribution of this work is a fully automated compilation algorithm, called \textsc{crane2}, which transforms the function definitions into C++ code equipped with arbitrary-precision arithmetic. These additions allow the new FOMC algorithm to scale to domain sizes over \num{500000} times larger than the current state of the art, as demonstrated through experimental results.
  
  
%While \textsc{crane} was shown to handle formulas beyond the capabilites of prior state of the art approaches, the \textsc{crane} still required manual evaluation of constructed functions to obtain model counts. The primary contribution of our work is a fully automated FOMC algorithm that relies on function construction. 
%  
%  the algorithm did not include base cases in the recursive definitions. This
%  work makes three contributions. First, we demonstrate how to construct
%  function definitions that include base cases by modifying the logical formulas
%  used in the FOMC algorithm. Second, we extend the well-known circuit
%  modification technique in knowledge compilation, known as smoothing, to work
%  with the formulas corresponding to base cases. Third, we introduce a
%  compilation algorithm that transforms the function definitions into C++ code,
%  equipped with arbitrary-precision arithmetic. These additions allow the new
%  FOMC algorithm to scale to domain sizes over \num{500000} times larger than
%  the current state of the art, as demonstrated through experimental results.
\end{abstract}

\section{Introduction}

% 1. What is the problem?

\emph{First-order model counting} (FOMC) is the task of counting the number of
models of a sentence in first-order logic over some given domain(s). The
weighted variant of this problem, known as WFOMC, seeks to compute the total
weight of the models~\cite{DBLP:conf/ijcai/BroeckTMDR11}. WFOMC is related to
its propositional predecessor weighted model
counting~\cite{DBLP:journals/ai/ChaviraD08} and other attempts to unify logic
and
probability~\cite{DBLP:journals/ai/Nilsson86,novak2012mathematical,vsaletic2024graded}.
It is also a key approach to \emph{lifted inference}, which aims to compute
probabilities more efficiently by leveraging symmetries in the
problem~\cite{DBLP:conf/ecai/Kersting12}.

% 2. Why is it interesting and important?

Lifted inference is an active area of research, with recent work in domains such
as constraint satisfaction problems~\cite{DBLP:journals/jair/TotisDRK23} and
probabilistic answer set programming~\cite{DBLP:journals/ijar/AzzoliniR23}.
WFOMC has been used for inference on probabilistic
databases~\cite{DBLP:journals/debu/GribkoffSB14} and probabilistic logic
programs~\cite{DBLP:journals/ijar/RiguzziBZCL17}. FOMC algorithms have been
utilised for discovering new integer
sequences~\cite{DBLP:conf/ijcai/SvatosJT0K23}, and for
conjecturing~\cite{DBLP:conf/ilp/BarvinekB0ZK21} and
constructing~\cite{DBLP:conf/kr/DilkasB23} recurrence relations and other
recursive structures that describe these sequences. FOMC algorithms have also
been extended to perform
\emph{sampling}~\cite{DBLP:conf/aaai/WangB0K22,DBLP:conf/lics/WangP0K23}.

% By considering domains of increasing sizes, the FOMC of a formula can be seen
% as an integer sequence.

% 3. Why is it hard? (E.g., why do naive approaches fail?)

The complexity of FOMC is typically characterised in terms of \emph{data
  complexity}. If there is an algorithm that can compute the FOMC of a formula
in polynomial time with respect to the domain size(s), that formula is called
\emph{liftable}~\cite{DBLP:conf/starai/JaegerB12}.
\citeauthor{DBLP:conf/pods/BeameBGS15}~\shortcite{DBLP:conf/pods/BeameBGS15}
demonstrated the existence of an unliftable formula with three variables. It is
also known that formulas with up to two variables are
liftable~\cite{DBLP:conf/nips/Broeck11,DBLP:conf/kr/BroeckMD14}. The liftable
fragment of formulas with two variables has been expanded with various
axioms~\cite{DBLP:conf/aaai/TothK23,DBLP:journals/ai/BremenK23}, counting
quantifiers~\cite{DBLP:journals/jair/Kuzelka21} and in other
ways~\cite{DBLP:conf/nips/KazemiKBP16}.

% This involves fixing the formula and determining whether an
% algorithm exists that can compute the FOMC in time polynomial with respect to
% the domain size(s).

% 4. Why hasn't it been solved before? (Or, what's wrong with previous proposed
% solutions? How does mine differ?)

There are many FOMC algorithms with different underlying principles. Perhaps the
most prominent class of FOMC algorithms is based on \emph{first-order knowledge
  compilation} (FOKC). In this approach, the formula is compiled into a
representation (such as a circuit or graph) by applying \emph{compilation
  rules}. Algorithms in this class include
\textsc{ForcLift}~\cite{DBLP:conf/ijcai/BroeckTMDR11} and its extension
\textsc{Crane}~\cite{DBLP:conf/kr/DilkasB23}. Another FOMC algorithm,
\textsc{FastWFOMC}~\cite{DBLP:conf/uai/BremenK21}, is based on cell enumeration.
Other algorithms utilise local search~\cite{DBLP:journals/pvldb/NiuRDS11},
junction trees~\cite{DBLP:conf/aaai/VenugopalSG15}, Monte Carlo
sampling~\cite{DBLP:journals/cacm/GogateD16}, and anytime approximation via
upper/lower bound construction~\cite{DBLP:conf/ijcai/BremenK20}.

% This representation can then be used to compute the FOMC for any combination
% of domain sizes.

% The former compiles formulas into circuits, while the latter compiles them
% first to graphs and then to (algebraic) equations.

% 5. What are the key components of my approach and results? Also include any
% specific limitations.

The recently proposed \textsc{Crane} algorithm marked significant progress in
handling formulas beyond the capabilities of \textsc{FastWFOMC} and
\textsc{ForcLift}, yet it fell short in critical aspects. \textsc{Crane} was
incomplete since it could only construct function definitions, requiring users
to manually evaluate these functions to obtain model counts. This limitation
prevented \textsc{Crane} from serving as a convenient black box solution for
FOMC. Furthermore, it introduced recursive functions without defining necessary
base cases, adding further complexity to the users. In this work, we present
\Cranetwo{}, addressing these gaps and pushing scalability to unprecedented
levels. Unlike its predecessor, \Cranetwo{} is a fully automated FOMC algorithm,
capable of handling domain sizes over \num{500000} times larger than previous
algorithms.

\begin{figure*}[t]
  \centering
  \begin{tikzpicture}
    \node at (-1, 0) (formula) {$\phi$};
    \node[draw,rounded rectangle] at (3, 0) (compilewithbasecases) {\CompileWithBaseCases};
    \node[draw,rounded rectangle] at (9, 0) (compilation) {Compile to C++};

    \node[draw,rounded rectangle,dashed] at (12, 0) (cpp) {C++ code};
    \node at (12, -1) (sizes) {Domain sizes};

    \node at (15, 0) (count) {Model count};

    \node[draw,rounded rectangle] at (3, -2) (findbasecases) {\FindBaseCases};
    \node[draw,rounded rectangle,left = 0.1cm of findbasecases] (crane) {\Compile};
    \node[draw,rounded rectangle,right = 0.1cm of findbasecases] (propagate) {\Propagate};
    \node[draw,rounded rectangle,right = 0.1cm of propagate] (simplify) {\Simplify};

    \node[draw,fit={(compilewithbasecases) (compilation) (crane) (findbasecases) (propagate)},inner ysep=7pt,yshift=5pt] {};
    \node at (0.6, 0.5) {\Cranetwo};

    \draw[-Latex] (formula) -- (compilewithbasecases);
    \draw[-Latex] (compilewithbasecases) -- node[above] {$\mathcal{E}$} (compilation);
    \draw[-Latex] (compilation) -- (cpp);
    \draw[-Latex] (sizes) -- (cpp);
    \draw[-Latex] (cpp) -- (count);

    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,left] {uses} (crane);
    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,left] {uses} (findbasecases);
    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,left] {uses} (propagate);
    \draw[-Latex,dashed] (compilewithbasecases) -- node[midway,right] {uses} (simplify);
  \end{tikzpicture}
  \caption[]{The outline of using \Cranetwo{} to compute the model count of a formula $\phi$. First, the formula is compiled into a set of equations, which are then used to create a C++ program. This program can be executed with different command line arguments to calculate the model count of $\phi$ for different domain sizes. To accomplish this, the \CompileWithBaseCases function employs several components:
    \begin{enumerate*}[label=(\roman*)]
      \item the FOKC algorithm of \textsc{Crane},
      \item a procedure called \FindBaseCases, which identifies a sufficient set of base cases,
      \item a procedure called \Propagate, which constructs a formula corresponding to a given base case, and
      \item algebraic simplification techniques (denoted as \Simplify).
    \end{enumerate*}
  }\label{fig:overview}
\end{figure*}

\Cref{fig:overview} outlines the workflow of the new algorithm. In
\cref{sec:main}, we describe how \CompileWithBaseCases finds base cases for
recursive functions. \Cref{sec:smoothing} explains post-processing techniques to
preserve the correct model count. \Cref{sec:cpp} elucidates how function
definitions are compiled into C++ programs. Note that a solution to FOMC that
uses compilation to C++ has been considered
before~\cite{DBLP:conf/kr/KazemiP16}, however, the extent of formulas that could
be handled was limited. Finally, \cref{sec:experiments} presents experimental
results comparing \Cranetwo{} with other FOMC algorithms.

% by:
% \begin{enumerate*}[label=(\roman*)]
%   \item identifying a sufficient set of base cases for each function,
%   \item constructing formulas corresponding to these base cases,
%   and\label[step]{step2}
%   \item recursing on these new formulas.
% \end{enumerate*}

\section{Preliminaries}

In \cref{sec:logic}, we summarise the basic principles of first-order logic.
Then, in \cref{sec:threelogics}, we formally define (W)FOMC and discuss the
distinctions between three variations of first-order logic used for FOMC.\@
Finally, in \cref{sec:algebra}, we introduce the terminology used to describe
the output of the original \textsc{Crane} algorithm, i.e., functions and
equations that define them.

We use $\mathbb{N}_{0}$ to represent the set of non-negative integers. In both
algebra and logic, we write $S\sigma$ to denote the application of a
\emph{substitution} $\sigma$ to an expression $S$, where
$\sigma = [x_{1} \mapsto y_{1}, x_{2} \mapsto y_{2}, \dots, x_{n} \mapsto y_{n}]$
signifies the replacement of all instances of $x_{i}$ with $y_{i}$ for all
$i = 1, \dots, n$.

\subsection{First-Order Logic}\label{sec:logic}

In this section, we will review the basic concepts of first-order logic as they
are used in FOKC algorithms. There are two key differences between the logic
used by these algorithms and the logic supported as input. First,
Skolemization~\cite{DBLP:conf/kr/BroeckMD14} eliminates existential quantifiers
by introducing additional predicates. Please note that Skolemization here
differs from the standard Skolemization procedure that introduces function
symbols~\cite{DBLP:books/daglib/0030198}. Second, the input formula is rewritten
as a conjunction of clauses, each in \emph{prenex normal
  form}~\cite{hinman2018fundamentals}.

A \emph{term} can be either a variable or a constant. An \emph{atom} can be
either
\begin{enumerate*}[label=(\roman*)]
  \item $P(t_{1}, \dots, t_{m})$ for some predicate $P$ and terms
  $t_{1}, \dots, t_{m}$ (written as $P(\mathbf{t})$ for short) or
  \item $x=y$ for some terms $x$ and $y$.
\end{enumerate*}
The \emph{arity} of a predicate is the number of arguments it takes, i.e., $m$
in the case of the predicate $P$ mentioned above. We write $P/m$ to denote a
predicate along with its arity. A \emph{literal} can be either an atom (i.e., a
\emph{positive} literal) or its negation (i.e., a \emph{negative} literal). An
atom is \emph{ground} if it contains no variables, i.e., only constants. A
\emph{clause} is of the form $\forall x_{1} \in \Delta_{1}\text{.
}\forall x_{2} \in \Delta_{2}\dots\text{ }\forall x_{n} \in \Delta_{n}\text{.
}\phi(x_{1}, x_{2}, \dots, x_{n})$, where $\phi$ is a disjunction of literals
that only contain variables $x_{1}, \dots, x_{n}$ (and any constants). We say
that a clause is a \emph{(positive) unit clause} if
\begin{enumerate*}[label=(\roman*)]
  \item there is only one literal with a predicate, and
  \item it is a positive literal.
\end{enumerate*}
Finally, a \emph{formula} is a conjunction of clauses. Throughout the paper, we
will use set-theoretic notation, interpreting a formula as a set of clauses and
a clause as a set of literals.

\subsection{FOMC Algorithms and Their Logics}\label{sec:threelogics}

\begin{table*}[t]
  \centering
  \begin{tabular}{llclll}
    \toprule
    Logic & Sorts & Constants & Variables & Quantifiers & Additional atoms\\
    \midrule
    \FO & one or more & \cmark & unlimited & $\forall$, $\exists$ & $x = y$\\
    \Ctwo & one & \xmark & two & $\forall$, $\exists$, $\exists^{= k}$, $\exists^{\le k}$, $\exists^{\ge k}$ & ---\\
    \UFO & one & \xmark & two & $\forall$ & $|P| = m$\\
    \bottomrule
  \end{tabular}
  \caption[]{A comparison of the three logics used in FOMC based on the following aspects:
    \begin{enumerate*}[label=(\roman*)]
      \item the number of sorts,
      \item support for constants,
      \item the maximum number of variables,
      \item supported quantifiers, and
      \item supported atoms in addition to those of the form $P(\mathbf{t})$ for a predicate $P/n$ and an $n$-tuple of terms $\mathbf{t}$.
    \end{enumerate*}
    Here:
    \begin{enumerate*}[label=(\roman*)]
      \item $k$ and $m$ are non-negative integers, with the latter depending on the domain size,
      \item $P$ represents a predicate, and
      \item $x$ and $y$ are terms.
    \end{enumerate*}
  }\label{tbl:logics}
\end{table*}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

In \cref{tbl:logics}, we outline the differences among three first-order logics
commonly used in FOMC:
\begin{enumerate*}[label=(\roman*)]
  \item \FO{} is the input format for
  \textsc{ForcLift}\footnote{\url{https://github.com/UCLA-StarAI/Forclift}} and
  its extensions
  \textsc{Crane}\footnote{\url{https://doi.org/10.5281/zenodo.8004077}} and
  \Cranetwo{};
  \item \Ctwo{} is often used in the literature on \textsc{FastWFOMC} and
  related
  methods~\cite{DBLP:journals/jair/Kuzelka21,DBLP:conf/aaai/MalhotraS22};
  \item \UFO{} is the input format supported by the most recent implementation
  of
  \textsc{FastWFOMC}\footnote{\url{https://github.com/jan-toth/FastWFOMC.jl}}.
\end{enumerate*}
The notation we use to refer to each logic is standard in the case of \Ctwo{}
and \UFO{}~\cite{tóth2024complexityweightedfirstordermodel} and redefined to be
more specific in the case of \FO{}. All three logics are function-free, and
domains are always assumed to be finite. As usual, we presuppose the
\emph{unique name assumption}, which states that two constants are equal if and
only if they are the same constant~\cite{DBLP:books/aw/RN2020}.

\renewcommand*{\thefootnote}{\arabic{footnote}}

In \FO{}, each term is assigned to a \emph{sort}, and each predicate $P/n$ is
assigned to a sequence of $n$ sorts. Each sort has its corresponding domain.
These assignments to sorts are typically left implicit and can be reconstructed
from the quantifiers. For example, $\forall x,y \in \Delta\text{. }P(x, y)$
implies that variables $x$ and $y$ have the same sort. On the other hand,
$\forall x \in \Delta\text{. }\forall y \in \Gamma\text{. } P(x, y)$ implies
that $x$ and $y$ have different sorts, and it would be improper to write, for
example, $\forall x \in \Delta\text{. }\forall y \in \Gamma\text{.
} P(x, y) \lor x = y$. \FO{} is also the only logic to support constants,
formulas with more than two variables, and the equality predicate. While we do
not explicitly refer to sorts in subsequent sections of this paper, the
many-sorted nature of \FO{} is paramount to the algorithms presented therein.

\begin{remark}
  In the case of \textsc{ForcLift} and its extensions, support for a formula as
  valid input does not imply that the algorithm can compile the formula into a
  circuit or graph suitable for lifted model counting. However, it is known that
  \textsc{ForcLift} compilation is guaranteed to succeed on any \FO{} formula
  without constants and with at most two
  variables~\cite{DBLP:conf/nips/Broeck11,DBLP:conf/kr/BroeckMD14}.
\end{remark}

Compared to \FO{}, \Ctwo{} and \UFO{} lack support for
\begin{enumerate*}[label=(\roman*)]
  \item constants,
  \item the equality predicate,
  \item multiple domains, and
  \item formulas with more than two variables.
\end{enumerate*}
The advantage that \Ctwo{} brings over \FO{} is the inclusion of \emph{counting
  quantifiers}. That is, alongside $\forall$ and $\exists$, \Ctwo{} supports
$\exists^{=k}$, $\exists^{\le k}$, and $\exists^{\ge k}$ for any positive
integer $k$. For example, $\exists^{=1} x\text{. }\phi(x)$ means that there
exists \emph{exactly one} $x$ such that $\phi(x)$, and $\exists^{\le 2} x\text{.
}\phi(x)$ means that there exist \emph{at most two} such $x$. \UFO{}, on the
other hand, does not support any existential quantifiers but instead
incorporates \emph{(equality) cardinality constraints}. For example, $|P| = 3$
constrains all models to have \emph{precisely three positive literals with the
  predicate $P$}.

\begin{definition}[Model]\label{def:model}
  Let $\phi$ be a formula in \FO{}. For each predicate $P/n$ in $\phi$, let
  ${(\Delta_{i}^{P})}_{i=1}^{n}$ be a list of the corresponding domains. Let
  $\sigma$ be a map from the domains of $\phi$ to their interpretations as sets,
  satisfying the following conditions:
  \begin{enumerate*}[label=(\roman*)]
    \item the sets are pairwise disjoint, and
    \item the constants in $\phi$ are included in the corresponding domains.
  \end{enumerate*}
  A \emph{structure} of $\phi$ is a set $M$ of ground literals defined by adding
  to $M$ either $P(\mathbf{t})$ or $\neg P(\mathbf{t})$ for every predicate
  $P/n$ in $\phi$ and $n$-tuple
  $\mathbf{t} \in \prod_{i=1}^{n} \sigma(\Delta_{i}^{P})$. A structure is a
  \emph{model} if it satisfies $\phi$.
\end{definition}

% (In practice, we typically only specify the size of each domain.)

\begin{remark}
  The distinctness of domains is important in two ways. First, in terms of
  expressiveness, a clause such as $\forall x \in \Delta\text{. }P(x, x)$ is
  valid if predicate $P$ is defined over two copies of the same domain and
  invalid otherwise. Second, having more distinct domains makes the problem more
  decomposable for the FOKC algorithm. With distinct domains, the algorithm can
  make assumptions or deductions about, e.g., the first domain of predicate $P$
  without worrying how (or if) they apply to the second domain.
\end{remark}

While this work focuses on FOMC, we still define the weighted variant of the
problem as Skolemization relies on weights even for unweighted FOMC.

\begin{definition}[WFOMC instance]\label{def:instance}
  A \emph{WFOMC instance} comprises:
  \begin{enumerate*}[label=(\roman*)]
    \item a formula $\phi$ in \FO{},
    \item two (rational) \emph{weights} $w^{+}(P)$ and $w^{-}(P)$ assigned to
    each predicate $P$ in $\phi$, and
    \item $\sigma$ as described in \cref{def:model}.
  \end{enumerate*}
  Unless specified otherwise, we assume all weights to be equal to 1.
\end{definition}

\begin{definition}[WFOMC~\cite{DBLP:conf/ijcai/BroeckTMDR11}]
  Given a WFOMC instance $(\phi, w^{+}, w^{-}, \sigma)$ as in
  \cref{def:instance}, the \emph{(symmetric) weighted first-order model count}
  (WFOMC) of $\phi$ is
  \begin{equation}\label{eq:wfomc}
    \sum_{M \models \phi} \prod_{P(\mathbf{t}) \in M} w^{+}(P) \prod_{\neg P(\mathbf{t}) \in M} w^{-}(P),
  \end{equation}
  where the sum is over all models of $\phi$.
\end{definition}

\begin{example}[Counting functions]\label{example:functions}
  To define predicate $P$ as a function from a domain $\Delta$ to itself, in
  \Ctwo{} one would write $\forall x \in \Delta\text{.
  }\exists^{=1} y \in \Delta\text{. }P(x, y)$. In \UFO{}, the same could be
  written as
  \begin{equation}\label[formula]{eq:functions1}
    \begin{gathered}
      (\forall x, y \in \Delta\text{. }S(x) \lor \neg P(x, y)) \land{}\\
      (|P| = |\Delta|),
    \end{gathered}
  \end{equation}
  where $w^{-}(S) = -1$. Although \cref{eq:functions1} has more models compared
  to its counterpart in \Ctwo{}, the negative weight $w^{-}(S) = -1$ makes some
  of the terms in \cref{eq:wfomc} cancel out.

  Equivalently, in \FO{} we would write
  \begin{equation}\label[formula]{eq:fo}
    \begin{gathered}
      (\forall x \in \Gamma\text{. }\exists y \in \Delta\text{. }P(x, y)) \land{}\\
      (\forall x \in \Gamma\text{. }\forall y, z \in \Delta\text{. }P(x, y) \land P(x, z) \Rightarrow y = z).
    \end{gathered}
  \end{equation}
  The first clause asserts that each $x$ must have at least one corresponding
  $y$, while the second statement adds the condition that if $x$ is mapped to
  both $y$ and $z$, then $y$ must equal $z$. It is important to note that
  \cref{eq:fo} is written with two domains instead of just one. However, we can
  still determine the correct number of functions by assuming that the sizes of
  $\Gamma$ and $\Delta$ are equal. This formulation, as observed by
  \citeauthor{DBLP:conf/kr/DilkasB23}~\shortcite{DBLP:conf/kr/DilkasB23}, can
  prove beneficial in enabling FOKC algorithms to find efficient solutions.
\end{example}

\subsection{Algebra}\label{sec:algebra}

We write $\expr{}$ to represent an arbitrary algebraic expression. It is
important to note that some terms have different meanings in algebra and
logic. In algebra, a \emph{constant} refers to a non-negative integer. Likewise,
a \emph{variable} can either be a parameter of a function or a variable
introduced through summation, such as $i$ in the expression
$\sum_{i=1}^{n} \expr$. A (function) \emph{signature} is
$f(x_{1}, \dots, x_{n})$ (or $f(\mathbf{x})$ for short), where $f$ represents an
$n$-ary function, and each $x_{i}$ represents a variable. An \emph{equation} is
$f(\mathbf{x}) = \expr{}$, with $f(\mathbf{x})$ representing a signature.

\begin{definition}[Base case]\label{def:basecase}
  Let $f(\mathbf{x})$ be a function call where each $x_{i}$ is either a constant
  or a variable (note that signatures are included in this definition). Then
  function call $f(\mathbf{y})$ is considered a \emph{base case} of
  $f(\mathbf{x})$ if $f(\mathbf{y}) = f(\mathbf{x})\sigma$, where $\sigma$ is a
  substitution that replaces one or more $x_{i}$ with a constant.
\end{definition}

\section{Completing the Definitions of Functions}\label{sec:main}

Before describing the main contribution of this work, let us review the
essential aspects of FOKC as realised by \textsc{Crane}. The input formula is
compiled into:
\begin{enumerate*}[label=(\roman*)]
  \item set $\mathcal{E}$ of equations,
  \item map $\mathcal{F}$ from function names to formulas, and
  \item map $\mathcal{D}$ from function names and argument indices to domains.
\end{enumerate*}
$\mathcal{E}$ can contain any number of functions, one of which (denoted by $f$)
represents the solution to the FOMC problem. To compute the FOMC for particular
domain sizes, $f$ must be evaluated with those domain sizes as arguments.
$\mathcal{D}$ records this correspondence between function arguments and
domains.

\begin{algorithm}[t]
  \caption{\protect\CompileWithBaseCases{$\phi$}}\label{alg:compilewithbasecases}
  \KwIn{formula $\phi$}
  \KwOut{set $\mathcal{E}$ of equations}
  $(\mathcal{E}, \mathcal{F}, \mathcal{D}) \gets \Compile{$\phi$}$\;\label{line:first}
  $\mathcal{E} \gets \Simplify{$\mathcal{E}$}$\;\label{line:second}
  \ForEach{base case $f(\mathbf{x}) \in \FindBaseCases{$\mathcal{E}$}$}{
    $\psi \gets \mathcal{F}(f)$\;
    \ForEach{index $i$ such that $x_{i} \in \mathbb{N}_{0}$}{\label{line:loop}
      $\psi \gets \Propagate{$\psi$, $\mathcal{D}(f, i)$, $x_i$}$\;
    }
    $\mathcal{E} \gets \mathcal{E} \cup \CompileWithBaseCases{$\psi$}$\;\label{line:final}
  }
\end{algorithm}

\Cref{alg:compilewithbasecases} presents our overall approach for compiling a
formula into equations that include the necessary base cases. To begin, we use
the FOKC algorithm of the original \textsc{Crane} to compile the formula into
the three components: $\mathcal{E}$, $\mathcal{F}$, and $\mathcal{D}$. After
some algebraic simplification, $\mathcal{E}$ is passed to the \FindBaseCases
procedure (see \cref{sec:identifying}). For each base case $f(\mathbf{x})$, we
retrieve the logical formula $\mathcal{F}(f)$ associated with the function name
$f$ and simplify it using the \Propagate procedure (explained in detail in
\cref{sec:simplifying}). We do this by iterating over all indices of
$\mathbf{x}$, where $x_{i}$ is a constant, and using \Propagate to simplify
$\psi$ by assuming that domain $\mathcal{D}(f, i)$ has size $x_{i}$. Finally, on
\cref{line:final}, \CompileWithBaseCases recurses on these simplified formulas
and adds the resulting base case equations to $\mathcal{E}$.
\Cref{example:overall} below provides more detail.

\begin{remark}
  Although \CompileWithBaseCases starts with a call to \textsc{Crane}, the
  proposed algorithm is not just a post-processing step for FOKC because
  \cref{alg:compilewithbasecases} is recursive and can issue more calls to
  \textsc{Crane} on various derived formulas.
\end{remark}

\begin{example}[Counting bijections]\label{example:overall}
  Consider the following formula (previously examined by
  \citeauthor{DBLP:conf/kr/DilkasB23}~\shortcite{DBLP:conf/kr/DilkasB23}) that
  defines predicate $P$ as a bijection between two sets $\Gamma$ and $\Delta$:
  \[
    \begin{gathered}
      (\forall x \in \Gamma\text{. }\exists y \in \Delta\text{. }P(x, y))\land{}\\
      (\forall y \in \Delta\text{. }\exists x \in \Gamma\text{. }P(x, y))\land{}\\
      (\forall x \in \Gamma\text{. }\forall y, z \in \Delta\text{. }P(x, y) \land P(x, z) \Rightarrow y = z)\land{}\\
      (\forall x, z \in \Gamma\text{. }\forall y \in \Delta\text{. }P(x, y) \land P(z, y) \Rightarrow x = z).
    \end{gathered}
  \]
  We specifically examine the first solution returned by \Cranetwo{} for this
  formula.

  After \cref{line:first,line:second}, we have
  \begin{align*}
    \mathcal{E} &= \left\{\,\begin{aligned}f(m, n) &= \sum_{l=0}^{n} \binom{n}{l}{(-1)}^{n-l}g(l, m),\\ g(l, m) &= g(l-1, m) + mg(l-1, m-1)\end{aligned}\,\right\};\\
    \mathcal{D} &= \{\, (f, 1) \mapsto \Gamma, (f, 2) \mapsto \Delta, (g, 1) \mapsto \Delta^{\top}, (g, 2) \mapsto \Gamma \,\},
  \end{align*}
  where $\Delta^{\top}$ is a new domain. (We omit the definition of
  $\mathcal{F}$ as the formulas can get a bit verbose.) Then \FindBaseCases
  identifies two base cases: $g(0, m)$ and $g(l, 0)$. In both cases,
  \CompileWithBaseCases recurses on the formula $\mathcal{F}(g)$ simplified by
  assuming that one of the domains is empty. In the first case, we recurse on
  the formula $\forall x \in \Gamma\text{. }S(x) \lor \neg S(x)$, where $S$ is a
  predicate introduced by Skolemization with weights $w^{+}(S) = 1$ and
  $w^{-}(S) = -1$. Hence, we obtain the base case $g(0, m) = 0^{m}$. In the case
  of $g(l, 0)$, \Propagate{$\psi$, $\Gamma$, $0$} returns an empty formula,
  resulting in $g(l, 0) = 1$.
\end{example}

It is worth noting that these base cases overlap when $l = m = 0$ but remain
consistent since $0^{0} = 1$. Generally, let $\phi$ be a formula with two
domains $\Gamma$ and $\Delta$, and let $n, m \in \mathbb{N}_{0}$. Then the FOMC
of \Propagate{$\phi$, $\Delta$, $n$} assuming $|\Gamma| = m$ is the same as the
FOMC of \Propagate{$\phi$, $\Gamma$, $m$} assuming $|\Delta| = n$.

Finally, the main responsibility of the \Simplify procedure is to handle the
algebraic pattern $\sum_{m=0}^{n}[a \le m \le b] f(m)$. Here:
\begin{enumerate*}[label=(\roman*)]
  \item $n$ is a variable,
  \item $a, b \in \mathbb{N}_{0}$ are constants,
  \item $f$ is an expression that may depend on $m$, and
  \item $[a \le m \le b] =
  \begin{cases}
    1 & \text{if $a \le m \le b$} \\
    0 & \text{otherwise}
  \end{cases}$.
\end{enumerate*}
\Simplify transforms this pattern into
$f(a) + f(a+1) + \cdots + f(\min\{\, n, b \,\})$. For instance, in the case of
\cref{example:overall}, \Simplify transforms
$g(l, m) = \sum_{k=0}^{m}[0 \le k \le 1]\binom{m}{k}g(l-1, m-k)$ into
$g(l, m) = g(l-1, m) + mg(l-1, m-1)$.

\subsection{Identifying a Sufficient Set of Base Cases}\label{sec:identifying}

\begin{algorithm}[t]
  \caption{\protect\FindBaseCases{$\mathcal{E}$}}\label{alg:findbasecases}
  \KwIn{set $\mathcal{E}$ of equations}
  \KwOut{set $\mathcal{B}$ of base cases}

  $\mathcal{B} \gets \emptyset$\;
  \ForEach{function call $f(\mathbf{y})$ on the right-hand side of an equation in $\mathcal{E}$}{\label{line:functioncall}
    $\mathbf{x} \gets \text{the parameters of $f$ in its definition}$\;
    \ForEach{$y_{i} \in \mathbf{y}$} {
      \uIf{$y_{i} \in \mathbb{N}_{0}$}{
        $\mathcal{B} \gets \mathcal{B} \cup \{\, f(\mathbf{x})[x_{i} \mapsto y_{i}] \,\}$\;
      }
      \ElseIf{$y_{i} = x_{i} - c_{i}$ for some $c_{i} \in \mathbb{N}_{0}$}{
        \For{$j \gets 0$ \KwTo $c_{i} - 1$}{\label{line:lim}
          $\mathcal{B} \gets \mathcal{B} \cup \{\, f(\mathbf{x})[x_{i} \mapsto j] \,\}$\;\label{line:insert}
        }
      }
    }
  }
\end{algorithm}
% (later, let's not bother yet): replace x_i-c_i on Line 7 of Algorithm 2 with a
% generalisation of x_i that can be an arbitrary summation/subtraction of domain
% sizes (propagating this change to the rest of the paper, particularly
% Assumption 1, the proof of Lemma 1)

\Cref{alg:findbasecases} summarises the implementation of \FindBaseCases.
\FindBaseCases considers two types of arguments when a function $f$ calls itself
recursively:
\begin{enumerate*}[label=(\roman*)]
  \item constants and
  \item arguments of the form $x_{i} - c_{i}$, where $c_{i}$ is a constant and
  $x_{i}$ is the $i$-th argument of the signature of $f$.
\end{enumerate*}
When the argument is a constant $c_{i}$, a base case with $c_{i}$ is added. In
the second case, a base case is added for each constant from $0$ up to (but not
including) $c_{i}$.

\begin{example}
  Consider the recursive function $g$ from \cref{example:overall}.
  \FindBaseCases iterates over two function calls: $g(l-1, m)$ and
  $g(l-1, m-1)$. The former produces the base case $g(0, m)$, while the latter
  produces both $g(0, m)$ and $g(l, 0)$.
\end{example}

It can be shown that the base cases identified by \FindBaseCases are sufficient
for the algorithm to terminate.\footnote{Note that characterising the
  fine-grained complexity of the solutions found by \Cranetwo{} or other FOMC
  algorithms is an emerging area of research. These questions have been
  partially addressed in previous
  work~\cite{DBLP:conf/kr/DilkasB23,tóth2024complexityweightedfirstordermodel}
  and are orthogonal to the goals of this section.}

\begin{theorem}[Termination]\label{thm:halting}
  Let $\mathcal{E}$ represent the equations returned by \CompileWithBaseCases.
  Let $f$ be an $n$-ary function in $\mathcal{E}$ and
  $\mathbf{x} \in \mathbb{N}_{0}^{n}$. Then the evaluation of $f(\mathbf{x})$
  terminates.
\end{theorem}

We prove \cref{thm:halting} using double induction. First, we apply induction to
the number of functions in $\mathcal{E}$. Then, we use induction on the arity of
the `last' function in $\mathcal{E}$ according to some topological ordering. For
the detailed proof, please refer to the technical appendix.

\subsection{Propagating Domain Size Assumptions}\label{sec:simplifying}

\begin{algorithm}[t]
  \caption{\protect\Propagate{$\phi$, $\Delta$, $n$}}\label{alg:propagate}
  \KwIn{formula $\phi$, domain $\Delta$, $n \in \mathbb{N}_{0}$}
  \KwOut{formula $\phi'$}
  $\phi' \gets \emptyset$\;
  \uIf{$n = 0$}{
    \ForEach{clause $C \in \phi$}{
      \lIf{$\Delta \not\in \Doms(C)$}{$\phi' \gets \phi' \cup \{\, C \,\}$}
      \Else{
        $C' \gets \{\, l \in C \mid \Delta \not\in \Doms(l) \,\}$\;
        \If{$C' \ne \emptyset$}{\label{line:presmoothing}
          $l \gets \text{an arbitrary literal in } C'$\;\label{line:smoothing1}
          $\phi' \gets \phi' \cup \{\, C' \cup \{\, \neg l \,\} \,\} $\;\label{line:smoothing2}
        }
      }
    }
  }
  \Else{
    $D \gets \text{a set of $n$ new constants in $\Delta$}$\;
    \ForEach{clause $C \in \phi$}{
      ${(x_{i})}_{i=1}^{m} \gets \text{the variables in $C$ with domain $\Delta$}$\;
      \lIf{$m = 0$}{$\phi' \gets \phi' \cup \{\, C \,\}$}
      \Else{
        $\phi' \gets \phi' \cup \{\, C[x_{1} \mapsto c_{1}, \dots, x_{m} \mapsto c_{m}] \mid {(c_{i})}_{i=1}^{m} \in D^{m} \,\}$\;
      }
    }
  }
\end{algorithm}

\Cref{alg:propagate}, called \Propagate, modifies the formula $\phi$ based on
the assumption that $|\Delta| = n$. When $n=0$, some clauses become vacuously
satisfied and can be removed. When $n > 0$, partial grounding is performed by
replacing all variables quantified over $\Delta$ with constants. (None of the
formulas examined in this work had $n > 1$.) \Cref{alg:propagate} handles these
two cases separately. For a literal or a clause $C$, the set of corresponding
domains is denoted as $\Doms(C)$.

In the case of $n = 0$, there are three types of clauses to consider:
\begin{enumerate*}[label=(\roman*)]
  \item those that do not mention $\Delta$,\label[type]{type1}
  \item those in which every literal contains variables quantified over
  $\Delta$, and\label[type]{type2}
  \item those that have some literals with variables quantified over $\Delta$
  and some without.\label[type]{type3}
\end{enumerate*}
Clauses of \cref{type1} are transferred to the new formula $\phi'$ without any
changes. For clauses of \cref{type2}, $C'$ is empty, so these clauses are
filtered out. As for clauses of \cref{type3}, a new kind of smoothing is
performed, which will be explained in \cref{sec:smoothing}.

In the case of $n>0$, $n$ new constants are introduced. Let $C$ be an arbitrary
clause in $\phi$, and let $m \in \mathbb{N}_{0}$ be the number of variables in
$C$ quantified over $\Delta$. If $m=0$, $C$ is added directly to $\phi'$.
Otherwise, a clause is added to $\phi'$ for every possible combination of
replacing the $m$ variables in $C$ with the $n$ new constants.

\begin{example}
  Let $C \equiv \forall x \in \Gamma\text{. }\forall y, z \in \Delta\text{.
  } \neg P(x, y) \lor \neg P(x, z) \lor y=z$. Then
  $\Doms(C) = \Doms(\neg P(x, y)) = \Doms(\neg P(x, z)) = \{\, \Gamma, \Delta \,\}$,
  and $\Doms(y=z) = \{\, \Delta \,\}$. A call to \Propagate{$\{\, C \,\}$,
    $\Delta$, $3$} would result in the following formula with nine clauses:
  \begin{align*}
    (\forall x \in \Gamma\text{. }\neg P(x, c_{1}) \lor& \neg P(x, c_{1}) \lor c_{1}=c_{1})\land{}\\
    (\forall x \in \Gamma\text{. }\neg P(x, c_{1}) \lor& \neg P(x, c_{2}) \lor c_{1}=c_{2})\land{}\\
    \vdots&\\
    (\forall x \in \Gamma\text{. }\neg P(x, c_{3}) \lor& \neg P(x, c_{3}) \lor c_{3}=c_{3}).\\
  \end{align*}
  Here, $c_{1}$, $c_{2}$, and $c_{3}$ are the new constants.
\end{example}

\section{Smoothing the Base Cases}\label{sec:smoothing}

\emph{Smoothing} modifies a circuit to reintroduce eliminated atoms, ensuring
the correct model
count~\cite{darwiche2001tractable,DBLP:conf/ijcai/BroeckTMDR11}. In this
section, we describe a similar process performed on
\cref{line:smoothing1,line:smoothing2} of \cref{alg:propagate}.
\Cref{line:presmoothing} checks if smoothing is necessary, and
\cref{line:smoothing1,line:smoothing2} execute it. If the condition on
\cref{line:presmoothing} is not satisfied, the clause is not smoothed but
omitted.

Suppose \Propagate is called with arguments $(\phi, \Delta, 0)$, i.e., we are
simplifying the formula $\phi$ by assuming that the domain $\Delta$ is empty.
Informally, if there is a predicate $P$ in $\phi$ unrelated to $\Delta$,
smoothing preserves all occurrences of $P$ even if all clauses with $P$ become
vacuously satisfied.

\begin{example}\label{example:basecasesmoothing}
  Let $\phi$ be:
  \begin{align}
    (\forall x \in \Delta\text{. }\forall y, z \in \Gamma&\text{. }Q(x) \lor P(y, z))\land{}\label[clause]{eq:example1}\\
    (\forall y, z \in \Gamma'&\text{. }P(y, z))\label[clause]{eq:example2},
  \end{align}
  where $\Gamma' \subseteq \Gamma$ is a domain introduced by a compilation rule.
  It should be noted that $P$, as a relation, is a subset of
  $\Gamma \times \Gamma$.

  Now, let us reason manually about the model count of $\phi$ when
  $\Delta = \emptyset$. Predicate $Q$ can only take one value, $Q = \emptyset$.
  The value of $P$ is fixed over $\Gamma' \times \Gamma'$ by \cref{eq:example2},
  but it can vary freely over
  $(\Gamma \times \Gamma) \setminus (\Gamma' \times \Gamma')$ since
  \cref{eq:example1} is vacuously satisfied by all structures. Therefore, the
  correct FOMC should be $2^{|\Gamma|^2 - |\Gamma'|^2}$. However, without
  \cref{line:smoothing2}, \Propagate would simplify $\phi$ to
  $\forall y, z \in \Gamma'\text{. }P(y, z)$. In this case, $P$ is a subset of
  $\Gamma' \times \Gamma'$. This simplified formula has only one model:
  $\{\, P(y, z) \mid y, z \in \Gamma' \,\}$. By including
  \cref{line:smoothing2}, \Propagate transforms $\phi$ to:
  \begin{gather*}
    (\forall y, z \in \Gamma\text{. }P(y, z) \lor \neg P(y, z))\land{}\\
    (\forall y, z \in \Gamma'\text{. }P(y, z)),
  \end{gather*}
  which retains the correct model count.
\end{example}

It is worth mentioning that the choice of $l$ on \cref{line:smoothing1} of
\cref{alg:propagate} is inconsequential because any choice achieves the same
goal: constructing a tautological clause that retains the literals in $C'$.

\section{Generating C++ Code}\label{sec:cpp}

In this section, we will describe the final step of \Cranetwo{} as outlined in
\cref{fig:overview}. This step involves translating the set of equations
$\mathcal{E}$ into C++ code. The resulting C++ program can then be compiled and
executed with different command-line arguments to compute the model count of the
formula for various domain sizes.

Each equation in $\mathcal{E}$ is compiled into a C++ function, along with a
separate cache for memoisation. Let us consider an arbitrary equation
$e = (f(\mathbf{x}) = \expr{}) \in \mathcal{E}$, and let
$\mathbf{c} \in \mathbb{N}_{0}^{n}$ represent the arguments of the corresponding
C++ function. The implementation of $e$ consists of three parts. First, we check
if $\mathbf{c}$ is already present in the cache of $e$. If it is, we simply
return the cached value. Second, for each base case $f(\mathbf{y})$ of
$f(\mathbf{x})$ (as defined in \cref{def:basecase}), we check if $\mathbf{c}$
\emph{matches} $\mathbf{y}$, i.e., $c_{i} = y_{i}$ whenever
$y_{i} \in \mathbb{N}_{0}$. If this condition is satisfied, $\mathbf{c}$ is
redirected to the C++ function that corresponds to the definition of the base
case $f(\mathbf{y})$. Finally, if none of the above cases apply, we evaluate
$\mathbf{c}$ based on the expression $\expr{}$, store the result in the cache,
and return it.

\section{Experimental Evaluation}\label{sec:experiments}

% 1. Introduction
% Objective: Briefly state the goals of the experiments.
% Overview: Summarize the structure of the section.

% 2. Experimental Setup

% Baselines: List and describe the baseline methods or systems used for
% comparison.

Our empirical evaluation sought to compare the runtime performance of {\Cranetwo} with the current state of the art, namely 
\textsc{FastWFOMC} and \textsc{ForcLift}. It is worth remarking that  \textsc{ForcLift} does not support arbitrary precision, and returns error for cases that requires arbitrary precision reasoning. 
Our experiments involve two versions
of \Cranetwo{}: \Cranegreedy{} and \Cranebfs{}. Like its predecessor,
\Cranetwo{} has two modes for applying compilation rules to formulas: one that
uses a greedy search algorithm similar to \textsc{ForcLift} and another that
combines greedy and breadth-first search.

The experiments were conducted using an Intel Skylake \SI{2.4}{\giga\hertz} CPU
with \SI{188}{\gibi\byte} of memory and CentOS~7. C++ programs were compiled
using the Intel C++ Compiler 2020u4. \textsc{FastWFOMC} ran on Julia~1.10.4,
while the other algorithms were executed on the Java Virtual Machine 1.8.0\_201.

% It would not make sense to include the original \textsc{Crane} algorithm in
% the experiments or evaluate \Cranetwo{} without the C++ code generation
% described in \cref{sec:cpp}. Indeed, these algorithms can only produce
% mathematical definitions of functions without evaluating them.

% While greedy search is more efficient (in terms of being able to handle larger
% formulas), it is a heuristic that can miss some solutions.

% Datasets: Provide details about the datasets used in the experiments,
% including size, source, and any preprocessing steps.

\subsection{Benchmarks}
We compare these algorithms using three benchmarks from previous studies. The
first benchmark is the function-counting problem from \cref{example:functions},
previously examined by
\citeauthor{DBLP:conf/kr/DilkasB23}~\shortcite{DBLP:conf/kr/DilkasB23}. The
second benchmark is a variant of the well-known `Friends and Smokers' Markov
logic network~\cite{DBLP:conf/aaai/SinglaD08,DBLP:conf/uai/BroeckCD12}. In
\Ctwo{}, \FO{}, and \UFO{}, this problem can be formulated as
\begin{gather*}
  (\forall x,y \in \Delta\text{. } S(x) \land F(x, y) \Rightarrow S(y)) \land{}\\
  (\forall x \in \Delta\text{. }S(x) \Rightarrow C(x))
\end{gather*}
or, equivalently, in conjunctive normal form as
\begin{gather*}
  (\forall x,y \in \Delta\text{. }S(y) \lor \neg S(x) \lor \neg F(x, y)) \land{}\\
  (\forall x \in \Delta\text{. } C(x) \lor \neg S(x)).
\end{gather*}
Finally, we include the bijection-counting problem previously utilised by
\citeauthor{DBLP:conf/kr/DilkasB23}~\shortcite{DBLP:conf/kr/DilkasB23}. Its
formulation in \FO{} is described in \cref{example:overall}. The equivalent
formula in \Ctwo{} is
\begin{align*}
  (\forall x \in \Delta\text{. }\exists^{=1} y \in \Delta&\text{. }P(x, y))\land{}\\
  (\forall y \in \Delta\text{. }\exists^{=1} x \in \Delta&\text{. }P(x, y)).
\end{align*}
Similarly, in \UFO{} the same formula can be written as
\begin{gather*}
  (\forall x, y \in \Delta\text{. }R(x) \lor \neg P(x, y))\land{}\\
  (\forall x, y \in \Delta\text{. }S(x) \lor \neg P(y, x))\land{}\\
  (|P| = |\Delta|),
\end{gather*}
where $w^{-}(R) = w^{-}(S) = -1$.

\begin{figure*}[t]
  \centering
  \includegraphics{plot.pdf}
  \caption{The runtime of the algorithms as a function of the domain size. Note
    that both axes are on a logarithmic scale.}\label{fig:plot}
\end{figure*}

%Since \textsc{FastWFOMC} does not support many-sorted logic, our experiments are
%limited to formulas with a single domain. However, many of the counting problems
%used in the experimental evaluation of
%\textsc{Crane}~\cite{DBLP:conf/kr/DilkasB23} become equivalent (in terms of
%generating equivalent integer sequences) when restricted to a single domain.
%Additionally, comparing \Cranetwo{} and \textsc{FastWFOMC} on a broader set of
%problems is challenging because each problem needs to be represented in two
%(quite different) logics: \FO{} and \UFO{}.

The three benchmark families cover a wide range of possibilities. The
`friends' benchmark stands out as it uses multiple predicates and can be
expressed in \FO{} using just two variables without cardinality constraints or
counting quantifiers. The `functions' benchmark, on the other hand, can still be
handled by all the algorithms, but it requires cardinality constraints, counting
quantifiers, or more than two variables. Lastly, the `bijections' benchmark is
an example of a formula that \textsc{FastWFOMC} can handle but \textsc{ForcLift}
cannot.

% Metrics: Define the performance metrics used to evaluate the results (e.g.,
% accuracy, precision, recall, F1-score, runtime).

%A considerable difference between \textsc{ForcLift} and the other two algorithms
%is that \textsc{ForcLift} does not support arbitrary precision whereas the other
%algorithms use the GNU Multiple Precision Arithmetic Library. Thus, when the
%count exceeds finite precision, \textsc{ForcLift} returns $\infty$. 

For
evaluation purposes, we ran each algorithm on each benchmark using domains of
sizes $2^{1}, 2^{2}, 2^{3}$, and so on, until an algorithm failed to handle a domain size due to timeout, out of memory error, or out of precision errors. While we separately measured compilation and inference time but primarily
focused on total runtime, dominated by the latter.

% Environment: Describe the hardware and software environment (e.g.,
% specifications of the computer, operating system, libraries, and tools used).



% 3. Results and Analysis
% Presentation of Results: Use tables, graphs, and charts to present the experimental results clearly.
% Comparison with Baselines: Compare your method’s results with the baselines.
% Discussion: Analyze and interpret the results, highlighting the strengths and potential weaknesses of your approach.
% Insights: Provide insights or patterns observed from the results.
% Challenges: Discuss any challenges or unexpected outcomes.
% Acknowledgement: Honestly acknowledge any limitations of your experiments or method.

\subsection{Results}
\Cref{fig:plot} presents a summary of the experimental results. Only
\textsc{FastWFOMC} and \Cranebfs{} could handle the bijection-counting problem.
For this benchmark, the largest domain sizes these algorithms could accommodate
were \num{64} and \num{4096}, respectively. On the other two benchmarks,
\textsc{ForcLift} had the lowest runtime. However, due to its finite precision,
it only scaled up to domain sizes of \num{16} and \num{128} for `friends' and
`functions', respectively. \textsc{FastWFOMC} outperformed \textsc{ForcLift} in
the case of `friends', but not `functions', as it could handle domains of size
\num{1024} and \num{64}, respectively. Furthermore, both \Cranebfs{} and
\Cranegreedy{} performed similarly on both benchmarks. Similarly to the
`bijections' benchmark, \Cranetwo{} significantly outperformed the other two
algorithms, scaling up to domains of size \num{8192} and \num{67108864},
respectively.

Another aspect of the experimental results that deserves separate discussion is
compilation. Both Julia and Scala use just-in-time (JIT) compilation, which
means that \textsc{FastWFOMC} and \textsc{ForcLift} take longer to run on the
smallest domain size, where most JIT compilation occurs. In the case of
\Cranetwo{}, it is only run once per benchmark, so the JIT compilation time is
included in its overall runtime across all domain sizes. Additionally, while
\textsc{ForcLift}'s compilation is generally faster than that of \Cranetwo{},
neither significantly affects overall runtime. Specifically, \textsc{ForcLift}
compilation typically takes around \SI{0.5}{\second}, while \Cranetwo{}
compilation takes around \SI{2.3}{\second}.

% 8. Conclusion
% Summary: Briefly summarize the key findings from the experimental results.
% Future Work: Suggest directions for future research based on your findings.

Based on our experiments, which algorithm should be used in practice? If the
formula can be handled by \textsc{ForcLift} and the domain sizes are reasonably
small, \textsc{ForcLift} is likely the fastest algorithm. In other situations,
\Cranetwo{} is expected to be significantly more efficient than
\textsc{FastWFOMC} regardless of domain size, provided both algorithms can
handle the formula.

\section{Conclusion and Future Work}

In this work, we present a scalable automated first-order knowledge compilation-based approach to first order model counting. The proposed approach relies on automatically generating the C++ code corresponding to the recursive functions extracted from knowledge compilation. The enusing empirical evaluatino demonstrated  that \Cranetwo{} can scale to much larger
domain sizes than \textsc{FastWFOMC} while handling more formulas than
\textsc{ForcLift}. Having FOMC algorithms that can efficiently handle large
domain sizes is especially crucial in the weighted setting. For example,
consider the `friends' instance examined in \cref{sec:experiments}, which models
a social network with friendships, smoking habits, and the probability of having
cancer. The utility of such a model would be significantly limited if
probabilities could only be efficiently computed for networks of at most
\num{1000} people.

There are many potential avenues for future work. Specifically, a more thorough
experimental study is needed to understand how FOMC algorithms compare in terms
of their ability to handle different formulas and their scalability with respect
to domain size. Additionally, further characterisation of the capabilities of
\Cranetwo{} can be explored. For example, \emph{completeness} could be proven
for a fragment of first-order logic such as \Ctwo{} (using a suitable encoding
of counting quantifiers). Moreover, the efficiency of a FOMC algorithm in
handling a particular formula can be assessed using \emph{fine-grained
  complexity}. In the case of \Cranetwo{}, this can be done by analysing the
equations~\cite{DBLP:conf/kr/DilkasB23}. By doing so, efficiency can be reasoned
about in a more implementation-independent manner by making claims about the
maximum degree of the polynomial that characterises any given solution.

\bibliography{paper}

\end{document}
